## Overview
The `map` crate implements gnomon's Hardy–Weinberg–standardized PCA pipeline.
It powers the `gnomon fit` and `gnomon project` subcommands and also offers
library APIs for model fitting, serialization, and projection. The
implementation streams genotype data in fixed-width blocks so it can operate on
everything from small cohorts to biobank-scale datasets, automatically choosing
between dense and iterative eigensolvers based on the requested number of
principal components.

## Why Hardy–Weinberg scaling?
Principal component analysis expects comparable per-locus variance. Genotype
counts drawn from a bi-allelic site follow the Hardy–Weinberg variance
`2p(1−p)` where `p` is the allele frequency. gnomon centers each locus and
divides by `√(2p(1−p))`, which keeps well-imputed common and rare variants on
the same footing without forcing mean imputation up front. This scaling also
means out-of-sample projections can reuse the same transformation without
recomputing cohort-specific statistics.

## CLI entry points
| Command | Purpose | Required input | Primary outputs |
| --- | --- | --- | --- |
| `gnomon fit --components <N> [--list PATH] [--ld] <GENOTYPE_PATH>` | Train a Hardy–Weinberg PCA model | Genotype source (PLINK trio or VCF/BCF files, local or remote) | `hwe.json`, `samples.tsv`, `hwe_summary.tsv` |
| `gnomon project <GENOTYPE_PATH>` | Project samples with an existing `hwe.json` located next to the genotype data | Matching genotype source aligned to the model's variant set | `projection_scores.tsv` (alignment diagnostics are library-only) |

Both commands print sample and variant counts, resolved source paths, and
stage-aware progress while running.

### `gnomon fit`
`gnomon fit` estimates the PCA loadings, explained variance, and per-locus
scalers and saves them as `hwe.json`. Use it when you want a reusable PCA basis
for later projections.

Required arguments:

* `GENOTYPE_PATH` – Path or URI pointing to the genotype data. Remote objects
  and per-chromosome directories are supported, as long as the loader can infer
  the associated `.bim`/`.fam` metadata or VCF headers.
* `--components <N>` – Number of principal components to retain in the model.

Optional arguments:

* `--list <PATH>` – Restrict fitting to a variant subset. The file (local or
  remote) should contain two whitespace-separated columns—chromosome and
  1-based position—with an optional header. Any variants that cannot be found
  are reported before the command exits.
* `--ld` – Enable linkage disequilibrium flattening. When present, LD weights
  use a default window of 51 variants unless `--sites_window <SITES>` (odd
  number of variants) or `--bp_window <BP>` (total genomic span in base pairs)
  is supplied. The resulting weights are stored inside `hwe.json` so projections
  can apply the same normalization.

### `gnomon project`
`gnomon project` projects new samples into the PCA space defined by a previously
fit model. Place the model files generated by `gnomon fit` (especially
`hwe.json`) alongside the genotype data being projected; the command validates
that the variant subsets match before producing scores. The CLI writes
`projection_scores.tsv`; alignment diagnostics can be requested through the
library API when finer-grained monitoring is needed.

## Fitting workflow
1. `gnomon fit` standardizes loci with the Hardy–Weinberg scaler (mean
   centering and division by √(2p(1−p))).  Missing data stay `NaN` until
   standardization, so they do not bias allele statistics.
2. A dense covariance build is attempted when the implied Gram matrix fits in
   memory; otherwise the partial self-adjoint eigensolver incrementally updates
   covariance from streamed blocks.
3. `--ld` enables LD weighting with either the default 51-variant window, a
   user-provided odd-sized site window, or a base-pair span that adapts to
   variant density. Windows are truncated near dataset edges and validated
   before use. The resulting per-variant weights are saved inside the
   serialized model.
4. Requested components beyond the intrinsic rank are clamped, and the driver
   reports the retained dimensionality.

### Outputs written next to the genotype source
* **`hwe.json`** – Serialized `HwePcaModel` capturing the scaler, eigenvalues,
  sample/variant counts, component loadings, optional LD weights, and the
  `(chromosome, position)` keys that identify the variant subset when filtering
  was enabled.
* **`samples.tsv`** – Tab-delimited manifest built from `.fam` content or the
  VCF/BCF sample list (`FID`, `IID`, `PAT`, `MAT`, `SEX`, `PHENOTYPE`).
* **`hwe_summary.tsv`** – Key/value table with overall counts, per-component
  explained variance, and explained-variance ratios.

## High-dimensionality projection
Because the biobank and the single individual are standardized on the same reference, and placed on the same per-axis scale, the directional geometry is preserved. Projecting onto the fitted biobank principal components means residual magnitude shrinkage is just a shared, axis-wise rescaling, so both a single new datapoint and the biobank data inhabit the same commensurately shrunken space and distances. Consequently, de-shrinkage or OADP/AP rotations would merely re-inflate coordinates and risk needless perturbation.

## Missing SNVs
If we project onto a unit vector made only from the SNVs we have, missing SNVs don’t contribute signal or variance; their loading mass is subtracted from the denominator and the axis is renormalized. The projection for each PC is then computed only from those overlapping SNVs, producing the same weighted sum we would obtain from mean-imputed, standardized genotypes before the final rescaling. We take the standardized genotype values at the overlapping loci, weight them by the corresponding loadings, and sum. Because loadings for missing loci were effectively dropped, we renormalize the axis using the amount of loading mass that remains—i.e., divide by the Euclidean norm of the retained loadings—so we're still projecting onto a unit-length axis defined solely by the SNVs we actually have. Drop missing SNVs, rebuild the axis from the overlap, rescale it to unit length.

## Alignment diagnostics
When projections encounter missing loci, gnomon keeps track of how much loading mass each sample retained on every component. That information can be exported via the library API by enabling `ProjectionOptions::return_alignment`, which produces `projection_alignment.tsv`. Each value represents the squared-norm scaling factor applied to keep the projection axis at unit length. Values near `1` indicate a complete overlap with the training loci, while smaller values highlight PCs that lost signal because of missing variants. The CLI defaults to score output only, but the saved model always contains enough metadata to reconstruct alignment diagnostics when requested.

## Projection workflow
* `gnomon project` loads `hwe.json`, reconstructs any stored variant subset, and
  verifies that the projection dataset supplies every required locus.  A
  mismatch fails fast instead of silently dropping variants.
* Projections reuse the block streaming interface, so missing loci are handled
  via the renormalization described above and the resulting scores share the
  training scale.
* The CLI writes `projection_scores.tsv`; callers that enable alignment
  diagnostics through the library API also receive `projection_alignment.tsv`.

## Progress and validation
The driver reports progress for allele statistics, optional LD weighting, Gram
matrix construction, and loading computation.  Stored models include
eigenvalues, explained-variance ratios, sample counts, variant counts (after
filtering), optional LD weights, and any variant key list.  Reloading verifies
that saved metadata are internally consistent and that projection datasets
match the recorded variant subset before computation begins, preventing
mismatched cohorts from being processed.
