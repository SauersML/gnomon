name: Rust Test CI
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened]
env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  # ======================================================================
  # JOB 1: Handles all Rust compilation, testing, and artifact creation.
  # ======================================================================
  build_and_test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Rust nightly
        uses: dtolnay/rust-toolchain@nightly

      - name: Generate cache keys
        id: cache_keys
        run: |
          SOURCE_HASH=$(find . -name "Cargo.toml" -o -name "Cargo.lock" -o -path "./src/*" -type f | sort | xargs cat | sha256sum | cut -d' ' -f1)
          echo "source_hash=$SOURCE_HASH" >> $GITHUB_OUTPUT
          DEPS_HASH=$(find . -name "Cargo.toml" -o -name "Cargo.lock" | sort | xargs cat | sha256sum | cut -d' ' -f1)
          echo "deps_hash=$DEPS_HASH" >> $GITHUB_OUTPUT
          echo "Source hash: $SOURCE_HASH"
          echo "Deps hash: $DEPS_HASH"

      - name: Cache release binary
        id: binary_cache
        uses: actions/cache@v4
        with:
          path: target/release/gnomon
          key: ${{ runner.os }}-release-binary-${{ steps.cache_keys.outputs.source_hash }}

      - name: Cache Cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry/index
            ~/.cargo/registry/cache
            ~/.cargo/git
          key: ${{ runner.os }}-cargo-registry-${{ steps.cache_keys.outputs.deps_hash }}
          restore-keys: |
            ${{ runner.os }}-cargo-registry-

      - name: Cache Cargo build
        uses: actions/cache@v4
        with:
          path: |
            target
            !target/release/gnomon
          key: ${{ runner.os }}-cargo-build-nightly-${{ steps.cache_keys.outputs.source_hash }}
          restore-keys: |
            ${{ runner.os }}-cargo-build-nightly-${{ steps.cache_keys.outputs.deps_hash }}
            ${{ runner.os }}-cargo-build-nightly-

      - name: Cache getdoc binary
        id: getdoc_cache
        uses: actions/cache@v4
        with:
          path: ~/.cargo/bin/getdoc
          key: ${{ runner.os }}-getdoc-v1

      - name: Install getdoc
        if: steps.getdoc_cache.outputs.cache-hit != 'true'
        run: |
          echo "Installing getdoc..."
          cargo +nightly install getdoc --locked

      - name: Run Rust unit tests
        id: test_step
        run: cargo +nightly test
        continue-on-error: true

      - name: Generate custom report with getdoc
        run: |
          ~/.cargo/bin/getdoc
          echo "=== Custom Report (getdoc) ==="
          cat report.md

      - name: Build Gnomon binaries
        run: |
          if [ "${{ steps.binary_cache.outputs.cache-hit }}" != "true" ]; then
            echo "Binary cache miss - building release binary..."
            cargo build --release
          fi
          echo "Building profiling binary (coz profile)..."
          cargo build --profile coz

      - name: Verify cached binary
        if: steps.binary_cache.outputs.cache-hit == 'true'
        run: |
          echo "Binary cache hit - verifying cached binary..."
          ls -la target/release/gnomon
          chmod +x target/release/gnomon
          ./target/release/gnomon --version || echo "Binary verification complete"

      - name: Fail job if unit tests failed
        if: steps.test_step.outcome == 'failure'
        run: exit 1

      - name: Upload build artifacts for all downstream jobs
        uses: actions/upload-artifact@v4
        with:
          name: build-output
          path: |
            target
            report.md
          retention-days: 1

  # ======================================================================
  # JOB 2-4: Python tests (unchanged, they are well-structured)
  # ======================================================================
  python_test_integration:
    runs-on: ubuntu-latest
    needs: build_and_test
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with: { name: build-output, path: . }
      - uses: actions/setup-python@v4
        with: { python-version: '3.13' }
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-integration-${{ hashFiles('test/test.py') }}
          restore-keys: |
            ${{ runner.os }}-pip-integration-
      - run: pip install pandas numpy requests psutil tabulate polars pyarrow
      - run: chmod +x target/release/gnomon
      - run: python -u test/test.py

  python_test_simulation:
    runs-on: ubuntu-latest
    needs: build_and_test
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with: { name: build-output, path: . }
      - uses: actions/setup-python@v4
        with: { python-version: '3.13' }
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-simulation-${{ hashFiles('test/sim_test.py') }}
          restore-keys: |
            ${{ runner.os }}-pip-simulation-
      - run: pip install pandas numpy requests psutil tabulate polars pyarrow gmpy2
      - run: chmod +x target/release/gnomon
      - id: sim_test
        run: python -u test/sim_test.py
      - if: failure()
        run: |
          echo "The simulation test failed. Checking for OOM errors in kernel logs..."
          sudo dmesg | grep -i -E 'killed process|out of memory' || echo "No OOM messages found."

  python_test_benchmark:
    runs-on: ubuntu-latest
    needs: build_and_test
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with: { name: build-output, path: . }
      - uses: actions/setup-python@v4
        with: { python-version: '3.13' }
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-benchmark-${{ hashFiles('test/bench.py') }}
          restore-keys: |
            ${{ runner.os }}-pip-benchmark-
      - run: pip install pandas numpy requests psutil tabulate polars pyarrow
      - run: chmod +x target/release/gnomon
      - run: python -u test/bench.py

  # ======================================================================
  # JOB 5: Performance Profiling (HEAVILY REVISED AND IMPROVED)
  # ======================================================================
  performance_reports:
    runs-on: ubuntu-latest
    needs: build_and_test
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with: { name: build-output, path: . }

      - name: Make profiling binary executable
        run: chmod +x target/coz/gnomon

      - name: Set up Python
        uses: actions/setup-python@v4
        with: { python-version: '3.11' }

      - name: Install Python dependencies
        run: pip install pandas numpy requests psutil

      - name: System Diagnostics
        run: |
          echo "--- System Information ---"
          echo "Kernel: $(uname -a)"
          echo "Distribution: $(lsb_release -a)"
          echo "CPU Cores: $(nproc)"
          echo "--- Filesystem ---"
          df -h
          echo "--- Memory ---"
          free -h
          echo "------------------------"

      - name: Get Kernel Version for Cache Key
        id: kernel_version
        run: echo "version=$(uname -r)" >> $GITHUB_OUTPUT
      
      - name: Cache APT packages for profiling
        id: apt_cache
        uses: actions/cache@v4
        with:
          path: |
            /var/cache/apt/archives
            /var/lib/apt/lists
          key: ${{ runner.os }}-apt-profiler-cache-${{ steps.kernel_version.outputs.version }}

      - name: Install Profiling Tools
        run: |
          echo "--- Installing Profiling Tools ---"
          
          # This variable holds the exact kernel version we are running
          CURRENT_KERNEL=$(uname -r)
          echo "Identified running kernel: $CURRENT_KERNEL"
          
          # The list of packages we need to ensure are installed
          REQUIRED_PACKAGES="coz-profiler linux-tools-common linux-tools-${CURRENT_KERNEL}"
          echo "Required packages: ${REQUIRED_PACKAGES}"
          
          # Only run apt-get update if the cache was not restored
          if [ "${{ steps.apt_cache.outputs.cache-hit }}" != 'true' ]; then
            echo "APT cache miss, running apt-get update..."
            sudo apt-get update
          else
            echo "APT cache hit, skipping apt-get update."
          fi
          
          # Install the specific packages needed. This is much more robust.
          # The `--no-install-recommends` flag keeps the install lean.
          sudo apt-get install -y --no-install-recommends ${REQUIRED_PACKAGES}
          
          echo "--- Verifying Installation ---"
          echo "Location of perf: $(which perf || echo 'not found')"
          echo "Version of perf: $(perf --version || echo 'not found')"
          echo "Installed linux-tools packages:"
          dpkg -l | grep 'linux-tools' || echo "No linux-tools packages found."
          echo "------------------------------"

      - name: Configure perf_event for Profilers
        run: |
          echo "--- Configuring perf_event_paranoid ---"
          echo "Value before change: $(cat /proc/sys/kernel/perf_event_paranoid)"
          # Both coz and perf require this permission level to collect performance data.
          sudo sh -c 'echo 1 >/proc/sys/kernel/perf_event_paranoid'
          echo "Value after change:  $(cat /proc/sys/kernel/perf_event_paranoid)"
          echo "---------------------------------------"

      - name: Run Profiling Harness
        run: |
          echo "--- Starting Profiling Harness ---"
          python test/perf.py --tool all
          echo "--- Profiling Harness Finished ---"
