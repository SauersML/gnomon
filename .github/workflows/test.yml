name: Rust Test CI
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches: [main]
    paths:
      - 'Cargo.toml'
      - 'Cargo.lock'
      - 'score/**'
      - 'test/**'
      - 'calibrate/**'
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened]
    paths:
      - 'Cargo.toml'
      - 'Cargo.lock'
      - 'score/**'
      - 'test/**'
      - 'calibrate/**'

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  # Help minimize network chatter in modern Cargo
  CARGO_REGISTRIES_CRATES_IO_PROTOCOL: sparse

jobs:
  build_and_test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Detect if any Rust-relevant files changed ------------------------------
      - name: Detect Rust source changes
        id: rust_changes
        uses: dorny/paths-filter@v2
        with:
          filters: |
            rust:
              - 'Cargo.toml'
              - 'Cargo.lock'
              - '**/*.rs'
      # -----------------------------------------------------------------------

      - name: Install Rust nightly
        if: steps.rust_changes.outputs.rust == 'true'
        uses: dtolnay/rust-toolchain@nightly

      - name: Prepare cache metadata
        id: cache_meta
        shell: bash
        run: |
          echo "week=$(date -u +%G%V)" >> $GITHUB_OUTPUT
          DEPS_HASH=$(find . -name "Cargo.toml" -o -name "Cargo.lock" | sort | xargs cat | sha256sum | cut -d' ' -f1)
          echo "deps_hash=$DEPS_HASH" >> $GITHUB_OUTPUT

      - name: Cache Cargo registry (CI speed only)
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry/index
            ~/.cargo/registry/cache
            ~/.cargo/git
          key: ${{ runner.os }}-cargo-registry-${{ steps.cache_meta.outputs.deps_hash }}
          restore-keys: |
            ${{ runner.os }}-cargo-registry-

      - name: Restore Cargo build cache (CI speed only)
        id: cargo_build_cache_restore
        uses: actions/cache/restore@v4
        with:
          path: target
          key: ${{ runner.os }}-cargo-build-nightly-${{ github.ref_name }}-W${{ steps.cache_meta.outputs.week }}-${{ github.run_id }}
          restore-keys: |
            ${{ runner.os }}-cargo-build-nightly-${{ github.ref_name }}-W${{ steps.cache_meta.outputs.week }}-
            ${{ runner.os }}-cargo-build-nightly-${{ github.ref_name }}-
            ${{ runner.os }}-cargo-build-nightly-

      # -------------------- PREWARM EVERYTHING (so artifacts are complete) --------------------
      - name: Cargo fetch (prepopulate deps cache)
        if: steps.rust_changes.outputs.rust == 'true'
        run: cargo +nightly fetch

        # Compile debug artifacts & tests (no-run) so target/debug tree is hot
      - name: Prebuild debug: lib/bin/tests (no run)
        if: steps.rust_changes.outputs.rust == 'true'
        run: |
          cargo +nightly build
          cargo +nightly test --no-run

        # Run real unit tests (as before)
      - name: Run Rust unit tests
        id: test_step
        if: steps.rust_changes.outputs.rust == 'true'
        run: cargo +nightly test --release -- --show-output
        continue-on-error: true

      # When no Rust changed, do “asm” analysis path (unchanged)
      - name: Inspect Assembly for Performance Analysis
        if: steps.rust_changes.outputs.rust == 'false'
        run: |
          cargo +nightly install cargo-show-asm --features disasm
          echo "--- Building test harness for inspection ---"
          cargo +nightly test --release --no-run
          TEST_HARNESS_PATH=$(find target/release/deps -name "gnomon-*" -type f -executable -print -quit)
          if [[ -z "$TEST_HARNESS_PATH" ]]; then
            echo "::error::Could not find compiled test harness."
            exit 1
          fi
          echo "Found test harness at: $TEST_HARNESS_PATH"
          echo "---"
          echo "--- ASSEMBLY FOR SIMD VERSION (from library) ---"
          echo "---"
          cargo asm -C lto=off --profile profiling --features no-inline-profiling --lib --intel gnomon::batch::process_tile

      # Optional: getdoc on failure (unchanged)
      - name: Cache getdoc binary
        id: getdoc_cache
        uses: actions/cache@v4
        with:
          path: ~/.cargo/bin/getdoc
          key: ${{ runner.os }}-getdoc-v1

      - name: Install getdoc
        if: steps.rust_changes.outputs.rust == 'true' && steps.getdoc_cache.outputs.cache-hit != 'true' && steps.test_step.outcome == 'failure'
        run: cargo +nightly install getdoc --locked

      - name: Generate custom report with getdoc
        if: steps.rust_changes.outputs.rust == 'true' && steps.test_step.outcome == 'failure'
        run: |
          ~/.cargo/bin/getdoc --features default
          cat report.md

      # Build release + profiling binaries (unchanged logic)
      - name: Build Gnomon binaries (Release and Profiling)
        if: steps.rust_changes.outputs.rust == 'true' && steps.test_step.outcome == 'success'
        run: |
          cargo +nightly build --release
          cargo +nightly build --profile profiling --features no-inline-profiling
      # ----------------------------------------------------------------------------------------

      - name: Save Cargo build cache (CI speed only)
        if: always()
        uses: actions/cache/save@v4
        with:
          path: target
          key: ${{ runner.os }}-cargo-build-nightly-${{ github.ref_name }}-W${{ steps.cache_meta.outputs.week }}-${{ github.run_id }}

      # -------------------- EXPORT: TAR EVERYTHING NEEDED FOR INSTANT LOCAL BUILDS --------------------
      - name: Compute safe artifact names (always)
        id: naming
        if: always()
        shell: bash
        run: |
          SAFE_REF="$(printf '%s' "${GITHUB_REF_NAME:-unknown}" | tr -c 'A-Za-z0-9_.-' '-')"
          SHORT_SHA="$(printf '%.12s' "${GITHUB_SHA}")"
          echo "safe_ref=$SAFE_REF" >> "$GITHUB_OUTPUT"
          echo "short_sha=$SHORT_SHA" >> "$GITHUB_OUTPUT"

      - name: Collect build metadata (always)
        if: always()
        shell: bash
        run: |
          mkdir -p export
          {
            echo "branch=${GITHUB_REF_NAME}"
            echo "branch_sanitized=${{ steps.naming.outputs.safe_ref }}"
            echo "commit=${GITHUB_SHA}"
            echo "short_commit=${{ steps.naming.outputs.short_sha }}"
            echo "week=${{ steps.cache_meta.outputs.week }}"
            echo "deps_hash=${{ steps.cache_meta.outputs.deps_hash }}"
            echo ""
            echo "--- rustc ---"
            (rustc -Vv || true)
            echo ""
            echo "--- cargo ---"
            (cargo -Vv || true)
            echo ""
            echo "--- host uname ---"
            (uname -a || true)
          } > export/build-meta.txt

      # The full deps mirror used by this run (registry + git)
      - name: Pack Cargo deps (~/.cargo/registry + ~/.cargo/git) (always)
        if: always()
        shell: bash
        run: |
          mkdir -p export
          if [[ -d "$HOME/.cargo" ]]; then
            tar --exclude="$HOME/.cargo/credentials" \
                -C "$HOME" -cf "export/cargo-deps-${{ steps.cache_meta.outputs.deps_hash }}.tar" \
                -h .cargo/registry .cargo/git 2>/dev/null || true
          fi
          ls -al export || true

      # Individual subtrees for targeted restores
      - name: Pack target/debug subtree (always)
        if: always()
        shell: bash
        run: |
          mkdir -p export
          if [[ -d target/debug ]]; then
            TAR="export/target-debug-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}.tar"
            tar -cf "$TAR" target/debug target/.rustc_info.json 2>/dev/null || tar -cf "$TAR" target/debug
          fi

      - name: Pack target/release subtree (always)
        if: always()
        shell: bash
        run: |
          mkdir -p export
          if [[ -d target/release ]]; then
            TAR="export/target-release-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}.tar"
            tar -cf "$TAR" target/release target/.rustc_info.json 2>/dev/null || tar -cf "$TAR" target/release
          fi

      - name: Pack target/profiling subtree (always)
        if: always()
        shell: bash
        run: |
          mkdir -p export
          if [[ -d target/profiling ]]; then
            TAR="export/target-profiling-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}.tar"
            tar -cf "$TAR" target/profiling
          fi

      # Entire target tree (debug + release + profiling + fingerprints + incremental)
      - name: Pack FULL target tree (always)
        if: always()
        shell: bash
        run: |
          mkdir -p export
          if [[ -d target ]]; then
            TAR="export/target-all-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}.tar"
            tar -cf "$TAR" target
          fi

      # Upload everything with sanitized names (no slashes) --------------------
      - name: Upload artifact – cargo deps (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cargo-deps-${{ steps.cache_meta.outputs.deps_hash }}
          path: export/cargo-deps-${{ steps.cache_meta.outputs.deps_hash }}.tar
          if-no-files-found: ignore
          retention-days: 14

      - name: Upload artifact – target debug (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: target-debug-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}
          path: export/target-debug-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}.tar
          if-no-files-found: ignore
          retention-days: 14

      - name: Upload artifact – target release (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: target-release-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}
          path: export/target-release-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}.tar
          if-no-files-found: ignore
          retention-days: 14

      - name: Upload artifact – target profiling (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: target-profiling-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}
          path: export/target-profiling-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}.tar
          if-no-files-found: ignore
          retention-days: 14

      - name: Upload artifact – target FULL tree (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: target-all-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}
          path: export/target-all-${{ steps.naming.outputs.safe_ref }}-W${{ steps.cache_meta.outputs.week }}.tar
          if-no-files-found: ignore
          retention-days: 14

      - name: Upload artifact – build metadata (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: build-meta-${{ steps.naming.outputs.safe_ref }}-${{ steps.naming.outputs.short_sha }}
          path: export/build-meta.txt
          retention-days: 30
      # -----------------------------------------------------------------------

      - name: Fail job if unit tests failed
        if: steps.rust_changes.outputs.rust == 'true' && steps.test_step.outcome == 'failure'
        run: exit 1

      - name: Upload build artifacts for all downstream jobs
        uses: actions/upload-artifact@v4
        with:
          name: build-output
          path: |
            target
            report.md
          retention-days: 1
          if-no-files-found: ignore   # safely handles “no rebuild” case

  python_test_integration:
    runs-on: ubuntu-latest
    needs: build_and_test
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: build-output
          path: .
      - uses: actions/setup-python@v4
        with: { python-version: '3.13' }
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-integration-${{ hashFiles('test/test.py') }}
          restore-keys: |
            ${{ runner.os }}-pip-integration-
      - run: pip install pandas numpy requests psutil tabulate polars pyarrow
      - run: chmod +x target/release/gnomon
      - run: python -u test/test.py

  python_test_simulation:
    runs-on: ubuntu-latest
    needs: build_and_test
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: build-output
          path: .
      - uses: actions/setup-python@v4
        with: { python-version: '3.13' }
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-simulation-${{ hashFiles('test/sim_test.py') }}
          restore-keys: |
            ${{ runner.os }}-pip-simulation-
      - run: pip install pandas numpy requests psutil tabulate polars pyarrow gmpy2
      - run: chmod +x target/release/gnomon
      - id: sim_test
        run: python -u test/sim_test.py
      - if: failure()
        run: |
          echo "The simulation test failed. Checking for OOM errors in kernel logs..."
          sudo dmesg | grep -i -E 'killed process|out of memory' || echo "No OOM messages found."

  python_test_benchmark:
    runs-on: ubuntu-latest
    needs: build_and_test
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: build-output
          path: .
      - uses: actions/setup-python@v4
        with: { python-version: '3.13' }
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-benchmark-${{ hashFiles('test/bench.py') }}
          restore-keys: |
            ${{ runner.os }}-pip-benchmark-
      - run: pip install pandas numpy requests psutil tabulate polars pyarrow
      - run: chmod +x target/release/gnomon
      - run: python -u test/bench.py

  performance_reports:
    runs-on: ubuntu-latest
    needs: build_and_test
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: build-output
          path: .

      - name: Make profiling binary executable
        run: chmod +x target/profiling/gnomon

      - uses: actions/setup-python@v4
        with: { python-version: '3.11' }

      - name: Install Python dependencies
        run: pip install pandas numpy requests psutil

      - name: System Diagnostics
        run: |
          echo "--- System Information ---"
          echo "Kernel: $(uname -a)"
          echo "Distribution: $(lsb_release -a || true)"
          echo "CPU Cores: $(nproc)"
          echo "--- Memory ---"
          free -h
          echo "------------------------"

      - name: Get Kernel Version for Cache Key
        id: kernel_version
        run: echo "version=$(uname -r)" >> $GITHUB_OUTPUT
      
      - name: Cache APT packages for perf
        id: apt_cache
        uses: actions/cache@v4
        with:
          path: |
            /var/cache/apt/archives
            /var/lib/apt/lists
          key: ${{ runner.os }}-apt-perf-tools-cache-${{ steps.kernel_version.outputs.version }}

      - name: Install Perf Tools
        run: |
          CURRENT_KERNEL=$(uname -r)
          REQUIRED_PACKAGES="linux-tools-common linux-tools-${CURRENT_KERNEL}"
          if [ "${{ steps.apt_cache.outputs.cache-hit }}" != 'true' ]; then
            sudo apt-get update -y
          fi
          sudo apt-get install -y --no-install-recommends ${REQUIRED_PACKAGES}
          perf --version

      - name: Configure Profiler Permissions
        run: |
          sudo sh -c 'echo -1 > /proc/sys/kernel/perf_event_paranoid'
          sudo sh -c 'echo 0 > /proc/sys/kernel/kptr_restrict'
          
      - name: Run Profiling Harness
        run: python test/perf.py
          
      - name: Grant Cache Permissions
        if: always()
        run: sudo chown -R runner:runner /var/cache/apt/archives /var/lib/apt/lists
          
      - name: Upload Profiling Data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-data-${{ github.run_id }}
          path: perf.data
          if-no-files-found: ignore
