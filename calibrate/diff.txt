diff --git a/calibrate/construction.rs b/calibrate/construction.rs
index 525f7dd..eaf475c 100644
--- a/calibrate/construction.rs
+++ b/calibrate/construction.rs
@@ -91,6 +91,8 @@ fn row_wise_tensor_product(a: &Array2<f64>, b: &Array2<f64>) -> Array2<f64> {
 pub struct ModelLayout {
     pub intercept_col: usize,
     pub pgs_main_cols: Range<usize>,
+    /// Unpenalized PC null-space columns (aligned with config.pc_configs order)
+    pub pc_null_cols: Vec<Range<usize>>,  
     pub penalty_map: Vec<PenalizedBlock>,
     pub total_coeffs: usize,
     pub num_penalties: usize,
@@ -122,7 +124,8 @@ impl ModelLayout {
     /// Enforces strict dimensional consistency across the entire GAM system.
     pub fn new(
         config: &ModelConfig,
-        pc_constrained_basis_ncols: &[usize],
+        pc_null_basis_ncols: &[usize],
+        pc_range_basis_ncols: &[usize],
         pgs_main_basis_ncols: usize,
         pc_unconstrained_basis_ncols: &[usize],
         num_pgs_interaction_bases: usize,
@@ -130,11 +133,16 @@ impl ModelLayout {
         let mut penalty_map = Vec::new();
         let mut current_col = 0;
         let mut penalty_idx_counter = 0;
+        let mut pc_null_cols: Vec<Range<usize>> = Vec::with_capacity(config.pc_configs.len());
 
         // Calculate total coefficients first to ensure consistency
         // Formula: total_coeffs = 1 (intercept) + p_pgs_main + p_pc_main + p_interactions
         let p_pgs_main = pgs_main_basis_ncols;
-        let p_pc_main: usize = pc_constrained_basis_ncols.iter().sum();
+        let p_pc_main: usize = pc_null_basis_ncols
+            .iter()
+            .zip(pc_range_basis_ncols.iter())
+            .map(|(n_null, n_range)| n_null + n_range)
+            .sum();
         // For tensor product interactions: each PC gets num_pgs_bases * num_pc_bases coefficients
         // Use unconstrained dimensions for interaction calculations
         let p_interactions: usize = pc_unconstrained_basis_ncols
@@ -146,16 +154,26 @@ impl ModelLayout {
         let intercept_col = current_col;
         current_col += 1;
 
-        // Main effect for each PC (each gets its own unique penalty index)
-        for (i, &num_basis) in pc_constrained_basis_ncols.iter().enumerate() {
-            let range = current_col..current_col + num_basis;
+        // Main effect for each PC (first reserve null/unpenalized, then range/penalized)
+        for (i, (&n_null, &n_range)) in pc_null_basis_ncols
+            .iter()
+            .zip(pc_range_basis_ncols.iter())
+            .enumerate()
+        {
+            // Null-space (unpenalized)
+            let null_range = current_col..current_col + n_null;
+            pc_null_cols.push(null_range.clone());
+            current_col += n_null;
+
+            // Range-space (penalized)
+            let range = current_col..current_col + n_range;
             penalty_map.push(PenalizedBlock {
                 term_name: format!("f({})", config.pc_configs[i].name),
                 col_range: range.clone(),
                 penalty_indices: vec![penalty_idx_counter], // Each PC main gets unique penalty index
                 term_type: TermType::PcMainEffect,
             });
-            current_col += num_basis;
+            current_col += n_range;
             penalty_idx_counter += 1; // Increment for next penalty
         }
 
@@ -195,6 +213,7 @@ impl ModelLayout {
         Ok(ModelLayout {
             intercept_col,
             pgs_main_cols,
+            pc_null_cols,
             penalty_map,
             total_coeffs: current_col,
             num_penalties: penalty_idx_counter,
@@ -217,6 +236,7 @@ pub fn build_design_and_penalty_matrices(
         HashMap<String, Array2<f64>>, // sum_to_zero_constraints
         HashMap<String, Array1<f64>>, // knot_vectors
         HashMap<String, Array2<f64>>, // range_transforms
+        HashMap<String, Array2<f64>>, // pc_null_transforms
         HashMap<String, Array1<f64>>, // interaction_centering_means
         HashMap<String, Array2<f64>>, // interaction_orth_alpha (per interaction block)
     ),
@@ -239,6 +259,7 @@ pub fn build_design_and_penalty_matrices(
     let mut sum_to_zero_constraints = HashMap::new();
     let mut knot_vectors = HashMap::new();
     let mut range_transforms = HashMap::new();
+    let mut pc_null_transforms: HashMap<String, Array2<f64>> = HashMap::new();
     let mut interaction_centering_means = HashMap::new();
     let mut interaction_orth_alpha: HashMap<String, Array2<f64>> = HashMap::new();
 
@@ -290,6 +311,7 @@ pub fn build_design_and_penalty_matrices(
 
     // 2. Generate range-only bases for PCs (functional ANOVA decomposition)
     let mut pc_range_bases = Vec::new();
+    let mut pc_null_bases: Vec<Option<Array2<f64>>> = Vec::new();
     let mut pc_unconstrained_bases_main = Vec::new();
 
     // Check if we have any PCs to process
@@ -337,18 +359,31 @@ pub fn build_design_and_penalty_matrices(
         // Create whitened range transform for PC main effects
         let s_pc_main =
             create_difference_penalty_matrix(pc_main_basis_unc.ncols(), config.penalty_order)?;
-        let (_, z_range_pc) = basis::null_range_whiten(&s_pc_main)?;
+        let (z_null_pc, z_range_pc) = basis::null_range_whiten(&s_pc_main)?;
 
         // PC main effect uses ONLY the range (penalized) part
         let pc_range_basis = pc_main_basis_unc.dot(&z_range_pc);
         pc_range_bases.push(pc_range_basis);
 
+        // Build null-space (if any)
+        if z_null_pc.ncols() > 0 {
+            let pc_null_basis = pc_main_basis_unc.dot(&z_null_pc);
+            pc_null_bases.push(Some(pc_null_basis));
+            pc_null_transforms.insert(pc_name.clone(), z_null_pc);
+        } else {
+            pc_null_bases.push(None);
+        }
+
         // Store PC range transformation for interactions and main effects
         range_transforms.insert(pc_name.clone(), z_range_pc);
     }
 
     // 3. Calculate layout first to determine matrix dimensions
     let pc_range_ncols: Vec<usize> = pc_range_bases.iter().map(|b| b.ncols()).collect();
+    let pc_null_ncols: Vec<usize> = pc_null_bases
+        .iter()
+        .map(|opt| opt.as_ref().map_or(0, |b| b.ncols()))
+        .collect();
     let pgs_range_ncols = range_transforms
         .get("pgs")
         .map(|rt| rt.ncols())
@@ -356,6 +391,7 @@ pub fn build_design_and_penalty_matrices(
 
     let layout = ModelLayout::new(
         config,
+        &pc_null_ncols,
         &pc_range_ncols,
         pgs_main_basis.ncols(),
         &pc_range_ncols, // Use range ncols for interactions too
@@ -415,15 +451,40 @@ pub fn build_design_and_penalty_matrices(
     // 1. Intercept - always the first column
     x_matrix.column_mut(layout.intercept_col).fill(1.0);
 
-    // 2. Main PC effects - use range-only bases (fully penalized)
+    // 2. Main PC effects: first unpenalized null-space (if any), then penalized range
     for (pc_idx, pc_config) in config.pc_configs.iter().enumerate() {
         let pc_name = &pc_config.name;
+        // Fill null-space columns
+        let null_cols = &layout.pc_null_cols[pc_idx];
+        if null_cols.len() > 0 {
+            if let Some(null_basis) = &pc_null_bases[pc_idx] {
+                if null_basis.nrows() != n_samples {
+                    return Err(EstimationError::LayoutError(format!(
+                        "PC null basis {} has {} rows but expected {} samples",
+                        pc_name,
+                        null_basis.nrows(),
+                        n_samples
+                    )));
+                }
+                if null_basis.ncols() != null_cols.len() {
+                    return Err(EstimationError::LayoutError(format!(
+                        "PC null basis {} has {} columns but layout expects {} columns",
+                        pc_name,
+                        null_basis.ncols(),
+                        null_cols.len()
+                    )));
+                }
+                x_matrix
+                    .slice_mut(s![.., null_cols.clone()])
+                    .assign(null_basis);
+            }
+        }
+        // Fill penalized range-space columns
         for block in &layout.penalty_map {
             if block.term_name == format!("f({pc_name})") {
                 let col_range = block.col_range.clone();
                 let pc_basis = &pc_range_bases[pc_idx];
 
-                // Validate dimensions before assignment
                 if pc_basis.nrows() != n_samples {
                     return Err(EstimationError::LayoutError(format!(
                         "PC range basis {} has {} rows but expected {} samples",
@@ -440,7 +501,6 @@ pub fn build_design_and_penalty_matrices(
                         col_range.len()
                     )));
                 }
-
                 x_matrix.slice_mut(s![.., col_range]).assign(pc_basis);
                 break;
             }
@@ -519,12 +579,11 @@ pub fn build_design_and_penalty_matrices(
                 )));
             }
 
-            // Build main-effect matrix M = [Intercept | PGS_main | PC_main_for_this_pc]
-            // Extract intercept
+            // Build main-effect matrix M = [Intercept | PGS_main | PC_main_for_this_pc (null + range)]
+            // Extract intercept and PGS main
             let intercept = x_matrix.slice(s![.., layout.intercept_col..layout.intercept_col + 1]).to_owned();
-            // Extract PGS main columns
             let pgs_main = x_matrix.slice(s![.., layout.pgs_main_cols.clone()]).to_owned();
-            // Extract this PC's main effect columns
+            // Extract this PC's main effect columns: null then range
             let pc_block = layout
                 .penalty_map
                 .iter()
@@ -534,15 +593,21 @@ pub fn build_design_and_penalty_matrices(
                     "Could not locate main-effect block for {} while building interaction orthogonalization",
                     pc_name
                 )))?;
-            let pc_main = x_matrix.slice(s![.., pc_block.col_range.clone()]).to_owned();
-
-            // Stack M columns in the order [Intercept | PGS_main | PC_main]
-            let m_cols: Vec<Array1<f64>> = intercept
-                .axis_iter(Axis(1))
-                .chain(pgs_main.axis_iter(Axis(1)))
-                .chain(pc_main.axis_iter(Axis(1)))
-                .map(|c| c.to_owned())
-                .collect();
+            let pc_null_cols = &layout.pc_null_cols[pc_idx];
+            let pc_null = if pc_null_cols.len() > 0 {
+                Some(x_matrix.slice(s![.., pc_null_cols.clone()]).to_owned())
+            } else {
+                None
+            };
+            let pc_range = x_matrix.slice(s![.., pc_block.col_range.clone()]).to_owned();
+
+            // Stack M columns in the order [Intercept | PGS_main | PC_null | PC_range]
+            let mut m_cols: Vec<Array1<f64>> = intercept.axis_iter(Axis(1)).map(|c| c.to_owned()).collect();
+            m_cols.extend(pgs_main.axis_iter(Axis(1)).map(|c| c.to_owned()));
+            if let Some(pc_n) = pc_null.as_ref() {
+                m_cols.extend(pc_n.axis_iter(Axis(1)).map(|c| c.to_owned()));
+            }
+            m_cols.extend(pc_range.axis_iter(Axis(1)).map(|c| c.to_owned()));
             let m_matrix = ndarray::stack(Axis(1), &m_cols.iter().map(|c| c.view()).collect::<Vec<_>>())
                 .map_err(|_| EstimationError::LayoutError("Failed to assemble interaction M matrix".to_string()))?;
 
@@ -620,6 +685,7 @@ pub fn build_design_and_penalty_matrices(
         sum_to_zero_constraints,
         knot_vectors,
         range_transforms,
+        pc_null_transforms,
         interaction_centering_means,
         interaction_orth_alpha,
     ))
@@ -1515,6 +1581,7 @@ mod tests {
             sum_to_zero_constraints: HashMap::new(),
             knot_vectors: HashMap::new(),
             range_transforms: HashMap::new(),
+            pc_null_transforms: HashMap::new(),
             interaction_centering_means: HashMap::new(),
             interaction_orth_alpha: HashMap::new(),
         };
@@ -1535,11 +1602,12 @@ mod tests {
         let pgs_main_coeffs =
             config.pgs_basis_config.num_knots + config.pgs_basis_config.degree - 1; // 6 - 1 - 1 = 4
 
-        // PC1 main is now range-only (penalized part only)
-        // Range dimension = main basis cols - null space dimension
+        // PC1 main now includes unpenalized null-space (after dropping intercept) and penalized range
+        // Range dimension = main basis cols - null space dimension; Null dim ≈ penalty_order - 1
         let pc1_main_basis_cols =
             config.pc_configs[0].basis_config.num_knots + config.pc_configs[0].basis_config.degree; // 5 - 1 = 4
         let r_pc = pc1_main_basis_cols - config.penalty_order; // 4 - 2 = 2
+        let n_pc = if config.penalty_order > 0 { config.penalty_order - 1 } else { 0 }; // for order=2 -> 1
 
         // Interaction is R×R (both dimensions use range-only)
         let pgs_main_basis_cols =
@@ -1547,7 +1615,7 @@ mod tests {
         let r_pgs = pgs_main_basis_cols - config.penalty_order; // 5 - 2 = 3
         let interaction_coeffs = r_pgs * r_pc; // 3 * 2 = 6
 
-        let expected_total_coeffs = 1 + pgs_main_coeffs + r_pc + interaction_coeffs; // 1 + 4 + 2 + 6 = 13
+        let expected_total_coeffs = 1 + pgs_main_coeffs + (n_pc + r_pc) + interaction_coeffs; // 1 + 4 + (1+2) + 6 = 14
         let expected_num_penalties = 2; // Individual: 1 for PC1 main + 1 for PC1×PGS interaction (whitened)
 
         assert_eq!(
@@ -1596,7 +1664,7 @@ mod tests {
     #[test]
     fn test_interaction_term_has_correct_penalty_structure() {
         let (data, config) = create_test_data_for_construction(100, 1);
-        let (_, s_list, layout, _, _, _, _, _) =
+        let (_, s_list, layout, _, _, _, _, _, _) =
             build_design_and_penalty_matrices(&data, &config).unwrap();
 
         // Expect one-penalty-per-interaction structure: 1 PC main + 1 interaction penalty = 2 total
@@ -1671,7 +1739,7 @@ mod tests {
     fn test_construction_with_no_pcs() {
         let (data, config) = create_test_data_for_construction(100, 0); // 0 PCs
 
-        let (_, _, layout, _, _, _, _, _) =
+        let (_, _, layout, _, _, _, _, _, _) =
             build_design_and_penalty_matrices(&data, &config).unwrap();
 
         let pgs_main_coeffs =
@@ -1697,7 +1765,7 @@ mod tests {
         // Build training matrices and transforms
         let (data, config) = create_test_data_for_construction(100, 1);
         // Use destructuring and explicitly name variables, but ignore with _ for the unused ones
-        let (x_training, _, _, sum_to_zero_constraints, knot_vectors, range_transforms, interaction_centering_means, _) = 
+        let (x_training, _, _, sum_to_zero_constraints, knot_vectors, range_transforms, pc_null_transforms, interaction_centering_means, _) = 
             build_design_and_penalty_matrices(&data, &config).unwrap();
 
         // Prepare a config carrying all saved transforms
@@ -1705,6 +1773,7 @@ mod tests {
         cfg.sum_to_zero_constraints = sum_to_zero_constraints.clone();
         cfg.knot_vectors = knot_vectors.clone();
         cfg.range_transforms = range_transforms.clone();
+        cfg.pc_null_transforms = pc_null_transforms.clone();
         cfg.interaction_centering_means = interaction_centering_means.clone();
 
         // Construct coefficients in the canonical structure
@@ -1723,6 +1792,11 @@ mod tests {
             .get(&pc_name)
             .expect("missing PC range transform")
             .ncols();
+        let n_pc = cfg
+            .pc_null_transforms
+            .get(&pc_name)
+            .map(|z| z.ncols())
+            .unwrap_or(0);
         let r_pgs = cfg
             .range_transforms
             .get("pgs")
@@ -1738,10 +1812,10 @@ mod tests {
                 pgs: (1..=pgs_dim).map(|i| i as f64).collect(),
                 pcs: {
                     let mut pcs = HashMap::new();
-                    pcs.insert(
-                        pc_name.clone(),
-                        (1..=r_pc).map(|i| 10.0 + i as f64).collect(),
-                    );
+                    let mut v: Vec<f64> = Vec::new();
+                    for i in 1..=n_pc { v.push(10.0 + i as f64); }
+                    for i in 1..=r_pc { v.push(20.0 + i as f64); }
+                    pcs.insert(pc_name.clone(), v);
                     pcs
                 },
             },
diff --git a/calibrate/estimate.rs b/calibrate/estimate.rs
index b1f92ac..60527e9 100644
--- a/calibrate/estimate.rs
+++ b/calibrate/estimate.rs
@@ -125,6 +125,7 @@ pub fn train_model(
         sum_to_zero_constraints,
         knot_vectors,
         range_transforms,
+        pc_null_transforms,
         interaction_centering_means,
         interaction_orth_alpha,
     ) = build_design_and_penalty_matrices(data, config)?;
@@ -578,6 +579,7 @@ pub fn train_model(
     config_with_constraints.range_transforms = range_transforms;
     config_with_constraints.interaction_centering_means = interaction_centering_means;
     config_with_constraints.interaction_orth_alpha = interaction_orth_alpha;
+    config_with_constraints.pc_null_transforms = pc_null_transforms;
 
     Ok(TrainedModel {
         config: config_with_constraints,
@@ -2053,6 +2055,7 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
@@ -2185,6 +2188,7 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
@@ -2297,11 +2301,12 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
 
-            let (x, s_list, layout, _, _, _, _, _) =
+            let (x, s_list, layout, _, _, _, _, _, _) =
                 build_design_and_penalty_matrices(&data, &config).unwrap();
 
             // Get P-IRLS result at a reasonable smoothing level
@@ -2397,11 +2402,12 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
 
-            let (x, s_list, layout, _, _, _, _, _) =
+            let (x, s_list, layout, _, _, _, _, _, _) =
                 build_design_and_penalty_matrices(&data, &config).unwrap();
 
             // Get P-IRLS result at a reasonable smoothing level
@@ -2513,6 +2519,7 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
@@ -2783,6 +2790,7 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
@@ -2896,12 +2904,13 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
 
             // --- 3. Build Model Structure ---
-            let (x_matrix, mut s_list, layout, _, _, _, _, _) =
+            let (x_matrix, mut s_list, layout, _, _, _, _, _, _) =
                 build_design_and_penalty_matrices(&data, &config).unwrap();
 
             assert!(
@@ -3102,6 +3111,7 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
@@ -3228,12 +3238,13 @@ pub mod internal {
                 sum_to_zero_constraints: HashMap::new(),
                 knot_vectors: HashMap::new(),
                 range_transforms: HashMap::new(),
+                pc_null_transforms: HashMap::new(),
                 interaction_centering_means: HashMap::new(),
                 interaction_orth_alpha: HashMap::new(),
             };
 
             // Test with extreme lambda values that might cause issues
-            let (x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _interaction_centering_means, _interaction_orth_alpha) =
+            let (x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _pc_null_transforms, _interaction_centering_means, _interaction_orth_alpha) =
                 build_design_and_penalty_matrices(&data, &config).unwrap();
 
             // Try with very large lambda values (exp(10) ~ 22000)
@@ -3357,12 +3368,13 @@ pub mod internal {
                 sum_to_zero_constraints: HashMap::new(),
                 knot_vectors: HashMap::new(),
                 range_transforms: HashMap::new(),
+                pc_null_transforms: HashMap::new(),
                 interaction_centering_means: HashMap::new(),
                 interaction_orth_alpha: HashMap::new(),
             };
 
             // Test that we can at least compute cost without getting infinity
-            let (x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _interaction_centering_means, _interaction_orth_alpha) =
+            let (x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _pc_null_transforms, _interaction_centering_means, _interaction_orth_alpha) =
                 build_design_and_penalty_matrices(&data, &config).unwrap();
 
             let reml_state = internal::RemlState::new(
@@ -3513,6 +3525,7 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
@@ -3631,6 +3644,7 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
@@ -3741,12 +3755,13 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
 
             // Build design and penalty matrices
-            let (x_matrix, s_list, layout, constraints, _knot_vectors, _range_transforms, _interaction_centering_means, _interaction_orth_alpha) =
+            let (x_matrix, s_list, layout, constraints, _knot_vectors, _range_transforms, _pc_null_transforms, _interaction_centering_means, _interaction_orth_alpha) =
                 internal::build_design_and_penalty_matrices(&training_data, &config)
                     .expect("Failed to build design matrix");
 
@@ -3879,6 +3894,7 @@ pub mod internal {
                     sum_to_zero_constraints: std::collections::HashMap::new(),
                     knot_vectors: std::collections::HashMap::new(),
                     range_transforms: std::collections::HashMap::new(),
+                    pc_null_transforms: std::collections::HashMap::new(),
                     interaction_centering_means: std::collections::HashMap::new(),
                     interaction_orth_alpha: std::collections::HashMap::new(),
                 };
@@ -3886,7 +3902,7 @@ pub mod internal {
                 simple_config.pgs_basis_config.num_knots = 4; // Use a reasonable number of knots
 
                 // 3. Build GUARANTEED CONSISTENT structures for this simple model.
-                let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
+                let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _pc_null_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
                     build_design_and_penalty_matrices(&data, &simple_config).unwrap_or_else(|e| {
                         panic!("Matrix build failed for {:?}: {:?}", link_function, e)
                     });
@@ -4013,15 +4029,16 @@ pub mod internal {
                     sum_to_zero_constraints: std::collections::HashMap::new(),
                     knot_vectors: std::collections::HashMap::new(),
                     range_transforms: std::collections::HashMap::new(),
-        interaction_centering_means: std::collections::HashMap::new(),
-        interaction_orth_alpha: std::collections::HashMap::new(),
-    };
+                    pc_null_transforms: std::collections::HashMap::new(),
+                    interaction_centering_means: std::collections::HashMap::new(),
+                    interaction_orth_alpha: std::collections::HashMap::new(),
+                };
 
                 // Use a simple basis with fewer knots to reduce complexity
                 simple_config.pgs_basis_config.num_knots = 3;
 
                 // 2. Generate consistent structures using the canonical function
-            let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
+            let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _pc_null_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
                 build_design_and_penalty_matrices(&data, &simple_config).unwrap_or_else(|e| {
                     panic!("Matrix build failed for {:?}: {:?}", link_function, e)
                 });
@@ -4181,6 +4198,7 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
@@ -4209,7 +4227,7 @@ pub mod internal {
             };
 
             // 2. Generate consistent structures using the canonical function
-            let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
+            let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _pc_null_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
                 build_design_and_penalty_matrices(&data, &simple_config)
                     .unwrap_or_else(|e| panic!("Matrix build failed: {:?}", e));
 
@@ -4363,12 +4381,13 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+        pc_null_transforms: std::collections::HashMap::new(),
         interaction_centering_means: std::collections::HashMap::new(),
         interaction_orth_alpha: std::collections::HashMap::new(),
     };
 
             // 2. Generate consistent structures using the canonical function
-            let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
+            let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _pc_null_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
                 build_design_and_penalty_matrices(&data, &simple_config)
                     .unwrap_or_else(|e| panic!("Matrix build failed: {:?}", e));
 
@@ -4477,12 +4496,13 @@ pub mod internal {
                 sum_to_zero_constraints: std::collections::HashMap::new(),
                 knot_vectors: std::collections::HashMap::new(),
                 range_transforms: std::collections::HashMap::new(),
+                pc_null_transforms: std::collections::HashMap::new(),
                 interaction_centering_means: std::collections::HashMap::new(),
                 interaction_orth_alpha: std::collections::HashMap::new(),
             };
 
             // 2. Generate consistent structures using the canonical function
-            let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
+            let (x_simple, s_list_simple, layout_simple, _sum_to_zero_constraints_simple, _knot_vectors_simple, _range_transforms_simple, _pc_null_transforms_simple, _interaction_centering_means_simple, _interaction_orth_alpha_simple) =
                 build_design_and_penalty_matrices(&data, &simple_config)
                     .unwrap_or_else(|e| panic!("Matrix build failed: {:?}", e));
 
@@ -4583,6 +4603,7 @@ fn test_train_model_fails_gracefully_on_perfect_separation() {
         sum_to_zero_constraints: HashMap::new(),
         knot_vectors: HashMap::new(),
         range_transforms: HashMap::new(),
+        pc_null_transforms: HashMap::new(),
         interaction_centering_means: HashMap::new(),
         interaction_orth_alpha: HashMap::new(),
     };
@@ -4661,13 +4682,14 @@ fn test_indefinite_hessian_detection_and_retreat() {
         sum_to_zero_constraints: std::collections::HashMap::new(),
         knot_vectors: std::collections::HashMap::new(),
         range_transforms: std::collections::HashMap::new(),
+        pc_null_transforms: std::collections::HashMap::new(),
         interaction_centering_means: std::collections::HashMap::new(),
         interaction_orth_alpha: std::collections::HashMap::new(),
     };
 
     // Try to build the matrices - if this fails, the test is still valid
             let matrices_result = build_design_and_penalty_matrices(&data, &config);
-    if let Ok((x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _interaction_centering_means, _interaction_orth_alpha)) = matrices_result {
+    if let Ok((x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _pc_null_transforms, _interaction_centering_means, _interaction_orth_alpha)) = matrices_result {
         let reml_state_result = RemlState::new(
             data.y.view(),
             x_matrix.view(),
@@ -4865,12 +4887,13 @@ mod optimizer_progress_tests {
             sum_to_zero_constraints: std::collections::HashMap::new(),
             knot_vectors: std::collections::HashMap::new(),
             range_transforms: std::collections::HashMap::new(),
+            pc_null_transforms: std::collections::HashMap::new(),
             interaction_centering_means: std::collections::HashMap::new(),
             interaction_orth_alpha: std::collections::HashMap::new(),
         };
 
         // 3) Build matrices and REML state to evaluate cost at specific rho
-        let (x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _interaction_centering_means, _interaction_orth_alpha) =
+        let (x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _pc_null_transforms, _interaction_centering_means, _interaction_orth_alpha) =
             build_design_and_penalty_matrices(&data, &config)?;
         let reml_state = internal::RemlState::new(
             data.y.view(),
@@ -4968,12 +4991,13 @@ mod gradient_validation_tests {
             sum_to_zero_constraints: std::collections::HashMap::new(),
             knot_vectors: std::collections::HashMap::new(),
             range_transforms: std::collections::HashMap::new(),
+            pc_null_transforms: std::collections::HashMap::new(),
             interaction_centering_means: std::collections::HashMap::new(),
             interaction_orth_alpha: std::collections::HashMap::new(),
         };
 
         // Build matrices and create REML state
-        let (x, s_list, layout, _sum_to_zero, _knots, _ranges, _int_means, _alphas) =
+        let (x, s_list, layout, _sum_to_zero, _knots, _ranges, _pc_null, _int_means, _alphas) =
             build_design_and_penalty_matrices(&data, &config).expect("matrix build");
         assert!(layout.num_penalties > 0, "Model must have at least one penalty");
 
diff --git a/calibrate/model.rs b/calibrate/model.rs
index fde7cfe..290329e 100644
--- a/calibrate/model.rs
+++ b/calibrate/model.rs
@@ -82,6 +82,11 @@ pub struct ModelConfig {
     /// Keyed by interaction term name (e.g., "f(PGS,PC1)"). Shape: m_cols x t_cols.
     #[serde(default)]
     pub interaction_orth_alpha: HashMap<String, Array2<f64>>,
+    /// Null-space transformation matrices for PC main effects (unpenalized part).
+    /// Maps PC name to Z_null (columns span the penalty null space after dropping intercept).
+    /// Optional for backward compatibility with older models.
+    #[serde(default)]
+    pub pc_null_transforms: HashMap<String, Array2<f64>>,
 }
 
 /// A structured representation of the fitted model coefficients, designed for
@@ -363,8 +368,9 @@ mod internal {
         // This closure was not used - removed
         // Previously defined a helper to fetch Z transform from model
 
-        // 2. Generate range-only bases for PCs (functional ANOVA approach)
+        // 2. Generate bases for PCs (functional ANOVA decomposition: null + range)
         let mut pc_range_bases = Vec::new();
+        let mut pc_null_bases: Vec<Option<Array2<f64>>> = Vec::new();
         let mut pc_unconstrained_bases_main = Vec::new();
         for i in 0..config.pc_configs.len() {
             let pc_col = pcs_new.column(i);
@@ -385,7 +391,7 @@ mod internal {
             let pc_main_basis_unc = pc_basis_unc.slice(s![.., 1..]);
             pc_unconstrained_bases_main.push(pc_main_basis_unc.to_owned());
 
-            // Apply the SAVED range transformation for functional ANOVA
+            // Apply the SAVED null and range transformations for functional ANOVA
             if let Some(range_transform) = config.range_transforms.get(pc_name) {
                 // Check dimensions before matrix multiplication to prevent panic
                 if pc_main_basis_unc.ncols() != range_transform.nrows() {
@@ -395,6 +401,16 @@ mod internal {
                 // Use range-only transformation for PC main effects (fully penalized)
                 let pc_range_basis = pc_main_basis_unc.dot(range_transform);
                 pc_range_bases.push(pc_range_basis);
+                // Build optional null-space basis if present
+                if let Some(z_null) = config.pc_null_transforms.get(pc_name) {
+                    if pc_main_basis_unc.ncols() != z_null.nrows() {
+                        return Err(ModelError::InternalStackingError);
+                    }
+                    let pc_null_basis = pc_main_basis_unc.dot(z_null);
+                    pc_null_bases.push(Some(pc_null_basis));
+                } else {
+                    pc_null_bases.push(None);
+                }
             } else {
                 // No range transform found for this PC
                 return Err(ModelError::ConstraintMissing(format!("range transform for {}", pc_name)));
@@ -408,9 +424,14 @@ mod internal {
         // 1. Intercept
         owned_cols.push(Array1::ones(n_samples));
 
-        // 2. Main PC effects (using range-only bases for functional ANOVA)
-        for pc_basis in &pc_range_bases {
-            for col in pc_basis.axis_iter(Axis(1)) {
+        // 2. Main PC effects per PC: null first (if any), then range
+        for pc_idx in 0..config.pc_configs.len() {
+            if let Some(ref null_basis) = pc_null_bases[pc_idx] {
+                for col in null_basis.axis_iter(Axis(1)) {
+                    owned_cols.push(col.to_owned());
+                }
+            }
+            for col in pc_range_bases[pc_idx].axis_iter(Axis(1)) {
                 owned_cols.push(col.to_owned());
             }
         }
@@ -457,16 +478,15 @@ mod internal {
 
                     // Apply stored orthogonalization to remove main-effect components (pure interaction)
                     if let Some(alpha) = config.interaction_orth_alpha.get(&tensor_key) {
-                        // Build M = [Intercept | PGS_main | PC_main_for_this_pc]
+                        // Build M = [Intercept | PGS_main | PC_main_for_this_pc (null + range)]
                         let intercept = Array1::ones(n_samples).insert_axis(Axis(1));
-                        // PGS_main is `pgs_main_basis` from above
-                        // PC_main_for_this_pc is `pc_range_bases[pc_idx]` from above
-                        let m_cols: Vec<Array1<f64>> = intercept
-                            .axis_iter(Axis(1))
-                            .chain(pgs_main_basis.axis_iter(Axis(1)))
-                            .chain(pc_range_bases[pc_idx].axis_iter(Axis(1)))
-                            .map(|c| c.to_owned())
-                            .collect();
+                        // PGS_main is `pgs_main_basis` from above; append PC null (if any) then PC range
+                        let mut m_cols: Vec<Array1<f64>> = intercept.axis_iter(Axis(1)).map(|c| c.to_owned()).collect();
+                        m_cols.extend(pgs_main_basis.axis_iter(Axis(1)).map(|c| c.to_owned()));
+                        if let Some(ref pc_null) = pc_null_bases[pc_idx] {
+                            m_cols.extend(pc_null.axis_iter(Axis(1)).map(|c| c.to_owned()));
+                        }
+                        m_cols.extend(pc_range_bases[pc_idx].axis_iter(Axis(1)).map(|c| c.to_owned()));
                         let m_matrix = ndarray::stack(
                             Axis(1),
                             &m_cols.iter().map(|c| c.view()).collect::<Vec<_>>(),
@@ -619,6 +639,7 @@ mod tests {
                     knots
                 },
                 range_transforms: HashMap::new(),
+                pc_null_transforms: HashMap::new(),
                 interaction_centering_means: HashMap::new(),
                 interaction_orth_alpha: HashMap::new(),
             },
@@ -694,6 +715,7 @@ mod tests {
                 sum_to_zero_constraints: HashMap::new(),
                 knot_vectors: HashMap::new(),
                 range_transforms: HashMap::new(),
+                pc_null_transforms: HashMap::new(),
                 interaction_centering_means: HashMap::new(),
                 interaction_orth_alpha: HashMap::new(),
             },
@@ -790,6 +812,7 @@ mod tests {
             sum_to_zero_constraints: HashMap::new(),
             knot_vectors: HashMap::new(),
             range_transforms: HashMap::new(),
+            pc_null_transforms: HashMap::new(),
             interaction_centering_means: HashMap::new(),
             interaction_orth_alpha: HashMap::new(),
         };
@@ -873,6 +896,7 @@ mod tests {
             sum_to_zero_constraints: HashMap::new(), // Will be populated by build_design_and_penalty_matrices
             knot_vectors: HashMap::new(), // Will be populated by build_design_and_penalty_matrices
             range_transforms: HashMap::new(), // Will be populated by build_design_and_penalty_matrices
+            pc_null_transforms: HashMap::new(),
             interaction_centering_means: HashMap::new(),
             interaction_orth_alpha: HashMap::new(),
         };
@@ -899,6 +923,7 @@ mod tests {
             sum_to_zero_constraints,
             knot_vectors,
             range_transforms,
+            pc_null_transforms,
             interaction_centering_means,
             interaction_orth_alpha,
         ) = crate::calibrate::construction::build_design_and_penalty_matrices(
@@ -926,6 +951,7 @@ mod tests {
                 sum_to_zero_constraints: sum_to_zero_constraints.clone(), // Clone the new field
                 knot_vectors, // Use the knot vectors generated by the model-building code
                 range_transforms: range_transforms.clone(), // Use full Option 3 pipeline
+                pc_null_transforms: pc_null_transforms.clone(),
                 interaction_centering_means: interaction_centering_means.clone(),
                 interaction_orth_alpha: interaction_orth_alpha.clone(),
             },
@@ -940,16 +966,20 @@ mod tests {
                         (1..=pgs_dim).map(|i| i as f64).collect()
                     },
                     pcs: {
-                        // Use range dimension for PC1 (Option 3)
-                        let pc1_dim = range_transforms.get("PC1").unwrap().ncols();
+                        // Use null + range dimension for PC1
+                        let pc1_dim_null = pc_null_transforms.get("PC1").map(|z| z.ncols()).unwrap_or(0);
+                        let pc1_dim_range = range_transforms.get("PC1").unwrap().ncols();
 
                         let mut pc_map = HashMap::new();
-                        pc_map.insert("PC1".to_string(), (1..=pc1_dim).map(|i| i as f64).collect());
+                        pc_map.insert(
+                            "PC1".to_string(),
+                            (1..=(pc1_dim_null + pc1_dim_range)).map(|i| i as f64).collect(),
+                        );
                         pc_map
                     },
                 },
                 interaction_effects: {
-                    // Option 3: Interaction term uses Range × Range dimensions
+                    // Interaction term uses Range × Range dimensions
                     let r_pgs = range_transforms.get("pgs").unwrap().ncols();
                     let r_pc1 = range_transforms.get("PC1").unwrap().ncols();
 
@@ -1116,11 +1146,12 @@ pub fn map_coefficients(
         pgs = beta.slice(s![layout.pgs_main_cols.clone()]).to_vec();
     }
 
+    // Iterate penalized blocks; for each PC main effect, prepend associated null-space coeffs
+    let mut pc_main_idx = 0usize;
     for block in &layout.penalty_map {
         let coeffs = beta.slice(s![block.col_range.clone()]).to_vec();
 
         use crate::calibrate::construction::TermType;
-        // This logic is now driven entirely by the term_type established in the layout
         match block.term_type {
             TermType::PcMainEffect => {
                 let pc_name = block
@@ -1128,10 +1159,19 @@ pub fn map_coefficients(
                     .trim_start_matches("f(")
                     .trim_end_matches(')')
                     .to_string();
-                pcs.insert(pc_name, coeffs);
+
+                // Fetch corresponding null-space coefficients (if any) by index
+                let null_range = &layout.pc_null_cols[pc_main_idx];
+                let mut full = Vec::new();
+                if null_range.len() > 0 {
+                    full.extend_from_slice(&beta.slice(s![null_range.clone()]).to_vec());
+                }
+                full.extend_from_slice(&coeffs);
+                pcs.insert(pc_name, full);
+
+                pc_main_idx += 1;
             }
             TermType::Interaction => {
-                // Tensor product interaction: f(PGS,PC1) -> direct storage
                 interaction_effects.insert(block.term_name.to_string(), coeffs);
             }
         }
diff --git a/calibrate/pirls.rs b/calibrate/pirls.rs
index 51b337e..3965443 100644
--- a/calibrate/pirls.rs
+++ b/calibrate/pirls.rs
@@ -1866,6 +1866,7 @@ mod tests {
             sum_to_zero_constraints: HashMap::new(),
             knot_vectors: HashMap::new(),
             range_transforms: HashMap::new(),
+            pc_null_transforms: HashMap::new(),
             interaction_centering_means: HashMap::new(),
             interaction_orth_alpha: HashMap::new(),
         };
@@ -2030,6 +2031,7 @@ mod tests {
         let layout = ModelLayout {
             intercept_col: 0,
             pgs_main_cols: 0..0,
+            pc_null_cols: vec![],
             penalty_map: vec![],
             total_coeffs: 2,
             num_penalties: 2,
@@ -2071,7 +2073,7 @@ mod tests {
         data: &TrainingData,
         config: &ModelConfig,
     ) -> Result<(Array2<f64>, Vec<Array2<f64>>, ModelLayout), Box<dyn std::error::Error>> {
-        let (x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _interaction_centering_means, _interaction_orth_alpha) =
+        let (x_matrix, s_list, layout, _sum_to_zero_constraints, _knot_vectors, _range_transforms, _pc_null_transforms, _interaction_centering_means, _interaction_orth_alpha) =
             build_design_and_penalty_matrices(data, config)?;
         let rs_original = compute_penalty_square_roots(&s_list)?;
         Ok((x_matrix, rs_original, layout))
@@ -2137,6 +2139,7 @@ mod tests {
         let layout = ModelLayout {
             intercept_col: 0,
             pgs_main_cols: 0..0,
+            pc_null_cols: vec![],
             penalty_map: vec![],
             total_coeffs: 2,
             num_penalties: 2,
@@ -2159,6 +2162,7 @@ mod tests {
             sum_to_zero_constraints: HashMap::new(),
             knot_vectors: HashMap::new(),
             range_transforms: HashMap::new(),
+            pc_null_transforms: HashMap::new(),
             interaction_centering_means: HashMap::new(),
             interaction_orth_alpha: HashMap::new(),
         };
@@ -2280,6 +2284,7 @@ mod tests {
             sum_to_zero_constraints: HashMap::new(),
             knot_vectors: HashMap::new(),
             range_transforms: HashMap::new(),
+            pc_null_transforms: HashMap::new(),
             interaction_centering_means: HashMap::new(),
             interaction_orth_alpha: HashMap::new(),
         };
@@ -2405,6 +2410,7 @@ mod tests {
             sum_to_zero_constraints: HashMap::new(),
             knot_vectors: HashMap::new(),
             range_transforms: HashMap::new(),
+            pc_null_transforms: HashMap::new(),
             interaction_centering_means: HashMap::new(),
             interaction_orth_alpha: HashMap::new(),
         };
@@ -2962,6 +2968,7 @@ mod tests {
         let layout = ModelLayout {
             intercept_col: 0,
             pgs_main_cols: 0..0,
+            pc_null_cols: vec![],
             penalty_map: vec![],
             total_coeffs: 2,
             num_penalties: 2,
diff --git a/src/main.rs b/src/main.rs
index c749bbe..cdc8ba5 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -142,6 +142,7 @@ pub fn train(args: TrainArgs) -> Result<(), Box<dyn std::error::Error>> {
         range_transforms: std::collections::HashMap::new(),
         interaction_centering_means: std::collections::HashMap::new(),
         interaction_orth_alpha: std::collections::HashMap::new(),
+        pc_null_transforms: std::collections::HashMap::new(),
     };
 
     // Train the final model
