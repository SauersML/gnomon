Rust for Cloud SDK overview

bookmark_border
Combine Rust's memory safety, concurrency, and performance with Google Cloud's scalable infrastructure and services. The Rust SDK supports Cloud Storage, Vertex AI, Secret Manager, and over 150 other services.

Features of the Rust SDK include:

Benefit from the efficiency of Rust: Use Rust's zero-cost abstractions and fine-grained memory management to build highly performant and resource-efficient applications, potentially lowering infrastructure costs.
Write more robust code: Rust's ownership model and type system help prevent common bugs like null pointer dereferences, data races, and memory leaks at compile time.
Build scalable applications: Build scalable applications capable of handling many requests simultaneously using Rust's async and await syntax and rich ecosystem, including the popular Tokio runtime.
Streamline your experience: Enjoy a developer experience supported by Cargo, Rust's package manager and build tool, a collection of crates, and strong community support.
Get knowledge and support: Google Cloud is committed to supporting Rust developers with idiomatic client libraries and tools.
Related products and tools
Cloud Run: Deploy containerized Rust web applications and services. Cloud Run scales automatically, so you only pay for what you use. Ideal for serverless Rust.
Google Kubernetes Engine (GKE): Orchestrate your containerized Rust applications using the power and flexibility of Kubernetes on Google's managed infrastructure.
Compute Engine: Gain control by running your Rust applications on virtual machines, configurable to your needs.
Cargo: Use Rust's built-in package manager to add Google Cloud client libraries and other dependencies to your project.
Docker: Package your Rust applications as container images for consistent and portable deployments on Cloud Run, GKE, and Compute Engine.



Get started with Rust

bookmark_border
Before you get started, you should meet the following prerequisites:

Install Rust. If you have not yet installed Rust, see the Rust documentation on Getting started.

You can confirm that you have Rust installed (and your version of Rust) with the following command:



cargo --version
Install an editor or IDE.

Install the Google Cloud CLI.

Create a new Rust project
To create a new Rust project, run the following command:



cargo new my-project
Change your directory to the new project by running the following command:



cd my-project
Install a Google Cloud Client Library
The Cloud Client Libraries for Rust is the idiomatic way for Rust developers to integrate with Google Cloud services, such as Secret Manager and Workflows.

Add the Secret Manager client library to your new project:



cargo add google-cloud-secretmanager-v1
If you haven't already enabled the Secret Manager API, enable it in APIs and services or by running the following command:



gcloud services enable secretmanager.googleapis.com
Add the google-cloud-gax crate to the new project:



cargo add google-cloud-gax
Add the tokio crate to the new project:



cargo add tokio --features macros
Edit src/main.rs in your project to use the Secret Manager client library:



#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    use google_cloud_gax::paginator::ItemPaginator as _;
    use google_cloud_secretmanager_v1::client::SecretManagerService;
    let project_id = std::env::args().nth(1).unwrap();
    let client = SecretManagerService::builder().build().await?;

    let mut items = client
        .list_secrets()
        .set_parent(format!("projects/{project_id}"))
        .by_item();
    while let Some(item) = items.next().await {
        println!("{}", item?.name);
    }
    Ok(())
}
Finally, build your program:



cargo build
The program should build without errors.

Running your Rust application
To use the Cloud Client Libraries in a local development environment, set up Application Default Credentials.

To set up Application Default Credentials, run the following command:



gcloud auth application-default login
Note: For more information, see Authenticate for using client libraries.
Run your program, supplying your Google Cloud project ID:



PROJECT_ID=$(gcloud config get project)
cargo run ${PROJECT_ID}
The program will print the secrets associated with your project ID. If you don't see any secrets, you might not have any in Secret Manager. Create a secret and rerun the program, and you should see the secret printed in the output.


Quickstart: Set up Rust on Cloud Shell

bookmark_border
Cloud Shell is a great environment to run small examples and tests. This guide shows you how to configure Rust and install one of the Cloud Client Libraries in Cloud Shell.

Start up Cloud Shell
In the Google Cloud console project selector , select a project.
Open https://shell.cloud.google.com to start a new shell. You might be prompted to authorize Cloud Shell to use your credentials for Google Cloud API calls.
Configure Rust
Cloud Shell comes with rustup pre-installed. You can use it to install and configure the default version of Rust:



rustup default stable
Confirm that you have the most recent version of Rust installed:



cargo --version
Install Rust client libraries in Cloud Shell
Create a new Rust project:



cargo new my-project
Change your directory to the new project:



cd my-project
Add the Secret Manager client library to the new project:



cargo add google-cloud-secretmanager-v1
Add the google-cloud-gax crate to the new project:



cargo add google-cloud-gax
Add the tokio crate to the new project:



cargo add tokio --features macros
Edit src/main.rs in your project to use the Secret Manager client library:



#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    use google_cloud_gax::paginator::ItemPaginator as _;
    use google_cloud_secretmanager_v1::client::SecretManagerService;
    let project_id = std::env::args().nth(1).unwrap();
    let client = SecretManagerService::builder().build().await?;

    let mut items = client
        .list_secrets()
        .set_parent(format!("projects/{project_id}"))
        .by_item();
    while let Some(item) = items.next().await {
        println!("{}", item?.name);
    }
    Ok(())
}
Run your program, supplying your Google Cloud project ID:



PROJECT_ID=$(gcloud config get project)
cargo run ${PROJECT_ID}
The program will print the secrets associated with your project ID. If you don't see any secrets, you might not have any in Secret Manager. Create a secret and rerun the program, and you should see the secret printed in the output.


Quickstart: Use Cloud Storage with Rust

bookmark_border
Google Cloud Storage is a managed service for storing unstructured data.

The Rust client library provides an idiomatic API to access this service. The client library resumes interrupted downloads and uploads, and automatically performs integrity checks on the data. For metadata operations, the client library can retry failed requests, and automatically poll long-running operations.

This guide shows you how to create a Cloud Storage bucket, upload an object to this bucket, and then read the object back.

Before you start this guide, create a Google Cloud project with billing enabled.

Add the client library dependency


cargo add google-cloud-storage
Create a storage bucket
The client to perform operations on buckets and object metadata is called StorageControl.



    use google_cloud_storage::model::{Bucket, bucket::IamConfig, bucket::iam_config::UniformBucketLevelAccess};
    use google_cloud_storage::client::StorageControl;
    let control = StorageControl::builder().build().await?;
To create a bucket, you must provide your project name and the bucket ID.



    let bucket = control
        .create_bucket()
        .set_parent("projects/_")
        .set_bucket_id(bucket_id)
        .set_bucket(
            gcs::model::Bucket::new()
                .set_project(format!("projects/{project_id}"))
        )
You can also provide other attributes for the bucket. For example, if you want all objects in the bucket to use the same permissions, you can enable Uniform bucket-level access.



    Bucket::new()
        .set_project(format!("projects/{project_id}"))
        .set_iam_config(
            IamConfig::new()
                .set_uniform_bucket_level_access(
                    UniformBucketLevelAccess::new()
                        .set_enabled(true),
            ),
        ),
Then send this request and wait for the response.



        .send()
        .await?;
    println!("bucket successfully created {bucket:?}");
Upload an object
The client to perform operations on object data is called Storage.



    use google_cloud_storage::client::Storage;
    let client = Storage::builder().build().await?;
In this case, you create an object called hello.txt with the greeting Hello World!.



    let object = client
        .upload_object(&bucket.name, "hello.txt", "Hello World!")
        .send_buffered()
        .await?;
    println!("object successfully uploaded {object:?}");
Download an object
To download the contents of an object, use the read_object() method.



    let mut reader = client.read_object(&bucket.name, "hello.txt").send().await?;
    let mut contents = Vec::new();
    while let Some(chunk) = reader.next().await.transpose()? {
        contents.extend_from_slice(&chunk);
    }
    println!(
        "object contents successfully downloaded {:?}",
        bytes::Bytes::from_owner(contents)
    );
Clean up resources
Finally, remove the object and bucket to clean up the resources used in this guide.



    control
        .delete_object()
        .set_bucket(&bucket.name)
        .set_object(&object.name)
        .set_generation(object.generation)
        .send()
        .await?;
    control
        .delete_bucket()
        .set_name(&bucket.name)
        .send()
        .await?;



How to initialize a client

bookmark_border
The Google Cloud Client Libraries for Rust use clients as the main abstraction to interface with specific services. Clients are implemented as Rust structs, with methods corresponding to each RPC offered by the service. To use a Google Cloud service using the Rust client libraries, you need to first initialize a client.

In this guide you'll initialize a client and then use the client to make an RPC using the Secret Manager API. The same structure applies to any other service in Google Cloud.

Before following this guide, you should do the following:

Follow one of the Secret Manager getting started guides, such as the guide on how to Create a secret. These guides cover service-specific concepts in more detail, and provide detailed guidance on project prerequisites.
Follow the instructions in the Authenticate for using client libraries guide. This guide will show you how to login to configure Application Default Credentials used in this guide.
Dependencies
With Rust, you must declare the dependency in your Cargo.toml file:



$ cargo add google-cloud-secretmanager-v1
To initialize a client, you first call Client::builder() to obtain an appropriate ClientBuilder and then call build() on that builder to create a client.

The following creates a client with the default configuration, which is designed to meet requirements for most use cases.



    let client = SecretManagerService::builder().build().await?;
Once the client is successfully initialized, you can use it to make RPCs:



    use google_cloud_gax::paginator::Paginator as _;
    let mut items = client
        .list_locations()
        .set_name(format!("projects/{project_id}"))
        .by_page();
    while let Some(page) = items.next().await {
        let page = page?;
        for location in page.locations {
            println!("{}", location.name);
        }
    }
This example shows a call to list_locations, which returns information about the supported locations for the service (in this case, Secret Manager).

The output of the example should look something like this:



projects/123456789012/locations/europe-west8
projects/123456789012/locations/europe-west9
projects/123456789012/locations/us-east5


Rust Cloud Client Libraries

bookmark_border
The Cloud Client Libraries are the recommended way to access Google Cloud APIs programmatically. The Cloud Client Libraries support accessing Google Cloud services in a way that significantly reduces the boilerplate code you have to write. The libraries provide high-level API abstractions so they're easier to understand. They embrace idioms of the language, work well with the standard library, and integrate better with your codebase.

For more information about client libraries for Cloud APIs, see Cloud Client Libraries explained.

Click an API to find out how to use it in Rust:

Search libraries and products
Libraries
google-cloud-iam-v1	google-cloud-iam-v1
google-cloud-location	google-cloud-location
google-cloud-longrunning	google-cloud-longrunning
google-cloud-aiplatform-v1	google-cloud-aiplatform-v1
google-cloud-language-v2	google-cloud-language-v2
google-cloud-secretmanager-v1	google-cloud-secretmanager-v1
google-cloud-speech-v2	google-cloud-speech-v2
google-cloud-storage	google-cloud-storage
google-cloud-sql-v1	google-cloud-sql-v1
google-cloud-telcoautomation-v1	google-cloud-telcoautomation-v1
google-cloud-workflows-v1	google-cloud-workflows-v1
google-cloud-workflows-executions-v1	google-cloud-workflows-executions-v1
google-cloud-iam-credentials-v1	google-cloud-iam-credentials-v1
google-cloud-apikeys-v2	google-cloud-apikeys-v2
google-cloud-api-cloudquotas-v1	google-cloud-api-cloudquotas-v1
google-cloud-api-servicecontrol-v1	google-cloud-api-servicecontrol-v1
google-cloud-api-servicecontrol-v2	google-cloud-api-servicecontrol-v2
google-cloud-api-servicemanagement-v1	google-cloud-api-servicemanagement-v1
google-cloud-api-serviceusage-v1	google-cloud-api-serviceusage-v1
google-cloud-appengine-v1	google-cloud-appengine-v1
google-cloud-bigtable-admin-v2	google-cloud-bigtable-admin-v2
google-cloud-accessapproval-v1	google-cloud-accessapproval-v1
google-cloud-advisorynotifications-v1	google-cloud-advisorynotifications-v1
google-cloud-alloydb-v1	google-cloud-alloydb-v1
google-cloud-apigateway-v1	google-cloud-apigateway-v1
google-cloud-apigeeconnect-v1	google-cloud-apigeeconnect-v1
google-cloud-apihub-v1	google-cloud-apihub-v1
google-cloud-apphub-v1	google-cloud-apphub-v1
google-cloud-identity-accesscontextmanager-v1	google-cloud-identity-accesscontextmanager-v1
google-cloud-osconfig-v1	google-cloud-osconfig-v1
google-cloud-asset-v1	google-cloud-asset-v1
google-cloud-assuredworkloads-v1	google-cloud-assuredworkloads-v1
google-cloud-backupdr-v1	google-cloud-backupdr-v1
google-cloud-baremetalsolution-v2	google-cloud-baremetalsolution-v2
google-cloud-beyondcorp-appconnections-v1	google-cloud-beyondcorp-appconnections-v1
google-cloud-beyondcorp-appconnectors-v1	google-cloud-beyondcorp-appconnectors-v1
google-cloud-beyondcorp-appgateways-v1	google-cloud-beyondcorp-appgateways-v1
google-cloud-beyondcorp-clientconnectorservices-v1	google-cloud-beyondcorp-clientconnectorservices-v1
google-cloud-beyondcorp-clientgateways-v1	google-cloud-beyondcorp-clientgateways-v1
google-cloud-bigquery-analyticshub-v1	google-cloud-bigquery-analyticshub-v1
google-cloud-bigquery-connection-v1	google-cloud-bigquery-connection-v1
google-cloud-bigquery-datapolicies-v1	google-cloud-bigquery-datapolicies-v1
google-cloud-bigquery-datapolicies-v2	google-cloud-bigquery-datapolicies-v2
google-cloud-bigquery-datatransfer-v1	google-cloud-bigquery-datatransfer-v1
google-cloud-bigquery-migration-v2	google-cloud-bigquery-migration-v2
google-cloud-bigquery-reservation-v1	google-cloud-bigquery-reservation-v1
google-cloud-billing-v1	google-cloud-billing-v1
google-cloud-grafeas-v1	google-cloud-grafeas-v1
google-cloud-binaryauthorization-v1	google-cloud-binaryauthorization-v1
google-cloud-certificatemanager-v1	google-cloud-certificatemanager-v1
google-cloud-chronicle-v1	google-cloud-chronicle-v1
google-cloud-cloudcontrolspartner-v1	google-cloud-cloudcontrolspartner-v1
google-cloud-clouddms-v1	google-cloud-clouddms-v1
google-cloud-cloudsecuritycompliance-v1	google-cloud-cloudsecuritycompliance-v1
google-cloud-commerce-consumer-procurement-v1	google-cloud-commerce-consumer-procurement-v1
google-cloud-confidentialcomputing-v1	google-cloud-confidentialcomputing-v1
google-cloud-config-v1	google-cloud-config-v1
google-cloud-configdelivery-v1	google-cloud-configdelivery-v1
google-cloud-connectors-v1	google-cloud-connectors-v1
google-cloud-contactcenterinsights-v1	google-cloud-contactcenterinsights-v1
google-cloud-datacatalog-lineage-v1	google-cloud-datacatalog-lineage-v1
google-cloud-datacatalog-v1	google-cloud-datacatalog-v1
google-cloud-dataform-v1	google-cloud-dataform-v1
google-cloud-datafusion-v1	google-cloud-datafusion-v1
google-cloud-dataplex-v1	google-cloud-dataplex-v1
google-cloud-dataproc-v1	google-cloud-dataproc-v1
google-cloud-datastream-v1	google-cloud-datastream-v1
google-cloud-deploy-v1	google-cloud-deploy-v1
google-cloud-developerconnect-v1	google-cloud-developerconnect-v1
google-cloud-devicestreaming-v1	google-cloud-devicestreaming-v1
google-cloud-dialogflow-cx-v3	google-cloud-dialogflow-cx-v3
google-cloud-dialogflow-v2	google-cloud-dialogflow-v2
google-cloud-discoveryengine-v1	google-cloud-discoveryengine-v1
google-cloud-documentai-v1	google-cloud-documentai-v1
google-cloud-domains-v1	google-cloud-domains-v1
google-cloud-edgecontainer-v1	google-cloud-edgecontainer-v1
google-cloud-edgenetwork-v1	google-cloud-edgenetwork-v1
google-cloud-essentialcontacts-v1	google-cloud-essentialcontacts-v1
google-cloud-eventarc-v1	google-cloud-eventarc-v1
google-cloud-filestore-v1	google-cloud-filestore-v1
google-cloud-financialservices-v1	google-cloud-financialservices-v1
google-cloud-functions-v2	google-cloud-functions-v2
google-cloud-gkebackup-v1	google-cloud-gkebackup-v1
google-cloud-gkeconnect-gateway-v1	google-cloud-gkeconnect-gateway-v1
google-cloud-gkehub-v1	google-cloud-gkehub-v1
google-cloud-gkemulticloud-v1	google-cloud-gkemulticloud-v1
google-cloud-gkerecommender-v1	google-cloud-gkerecommender-v1
google-cloud-gsuiteaddons-v1	google-cloud-gsuiteaddons-v1
google-cloud-iap-v1	google-cloud-iap-v1
google-cloud-ids-v1	google-cloud-ids-v1
google-cloud-kms-v1	google-cloud-kms-v1
google-cloud-kms-inventory-v1	google-cloud-kms-inventory-v1
google-cloud-licensemanager-v1	google-cloud-licensemanager-v1
google-cloud-lustre-v1	google-cloud-lustre-v1
google-cloud-managedidentities-v1	google-cloud-managedidentities-v1
google-cloud-managedkafka-schemaregistry-v1	google-cloud-managedkafka-schemaregistry-v1
google-cloud-managedkafka-v1	google-cloud-managedkafka-v1
google-cloud-memcache-v1	google-cloud-memcache-v1
google-cloud-memorystore-v1	google-cloud-memorystore-v1
google-cloud-metastore-v1	google-cloud-metastore-v1
google-cloud-migrationcenter-v1	google-cloud-migrationcenter-v1
google-cloud-modelarmor-v1	google-cloud-modelarmor-v1
google-cloud-netapp-v1	google-cloud-netapp-v1
google-cloud-networkconnectivity-v1	google-cloud-networkconnectivity-v1
google-cloud-networkmanagement-v1	google-cloud-networkmanagement-v1
google-cloud-networksecurity-v1	google-cloud-networksecurity-v1
google-cloud-networkservices-v1	google-cloud-networkservices-v1
google-cloud-notebooks-v2	google-cloud-notebooks-v2
google-cloud-optimization-v1	google-cloud-optimization-v1
google-cloud-oracledatabase-v1	google-cloud-oracledatabase-v1
google-cloud-orchestration-airflow-service-v1	google-cloud-orchestration-airflow-service-v1
google-cloud-orgpolicy-v2	google-cloud-orgpolicy-v2
google-cloud-oslogin-v1	google-cloud-oslogin-v1
google-cloud-parallelstore-v1	google-cloud-parallelstore-v1
google-cloud-parametermanager-v1	google-cloud-parametermanager-v1
google-cloud-policysimulator-v1	google-cloud-policysimulator-v1
google-cloud-iam-v2	google-cloud-iam-v2
google-cloud-policytroubleshooter-iam-v3	google-cloud-policytroubleshooter-iam-v3
google-cloud-policytroubleshooter-v1	google-cloud-policytroubleshooter-v1
google-cloud-privilegedaccessmanager-v1	google-cloud-privilegedaccessmanager-v1
google-cloud-rapidmigrationassessment-v1	google-cloud-rapidmigrationassessment-v1
google-cloud-recaptchaenterprise-v1	google-cloud-recaptchaenterprise-v1
google-cloud-recommender-v1	google-cloud-recommender-v1
google-cloud-redis-cluster-v1	google-cloud-redis-cluster-v1
google-cloud-redis-v1	google-cloud-redis-v1
google-cloud-resourcemanager-v3	google-cloud-resourcemanager-v3
google-cloud-retail-v2	google-cloud-retail-v2
google-cloud-run-v2	google-cloud-run-v2
google-cloud-scheduler-v1	google-cloud-scheduler-v1
google-cloud-securesourcemanager-v1	google-cloud-securesourcemanager-v1
google-cloud-security-privateca-v1	google-cloud-security-privateca-v1
google-cloud-security-publicca-v1	google-cloud-security-publicca-v1
google-cloud-securitycenter-v2	google-cloud-securitycenter-v2
google-cloud-securityposture-v1	google-cloud-securityposture-v1
google-cloud-servicedirectory-v1	google-cloud-servicedirectory-v1
google-cloud-servicehealth-v1	google-cloud-servicehealth-v1
google-cloud-shell-v1	google-cloud-shell-v1
google-cloud-storagebatchoperations-v1	google-cloud-storagebatchoperations-v1
google-cloud-storageinsights-v1	google-cloud-storageinsights-v1
google-cloud-support-v2	google-cloud-support-v2
google-cloud-talent-v4	google-cloud-talent-v4
google-cloud-tasks-v2	google-cloud-tasks-v2
google-cloud-texttospeech-v1	google-cloud-texttospeech-v1
google-cloud-timeseriesinsights-v1	google-cloud-timeseriesinsights-v1
google-cloud-tpu-v2	google-cloud-tpu-v2
google-cloud-translation-v3	google-cloud-translation-v3
google-cloud-video-livestream-v1	google-cloud-video-livestream-v1
google-cloud-video-stitcher-v1	google-cloud-video-stitcher-v1
google-cloud-video-transcoder-v1	google-cloud-video-transcoder-v1
google-cloud-videointelligence-v1	google-cloud-videointelligence-v1
google-cloud-vision-v1	google-cloud-vision-v1
google-cloud-vmmigration-v1	google-cloud-vmmigration-v1
google-cloud-vmwareengine-v1	google-cloud-vmwareengine-v1
google-cloud-vpcaccess-v1	google-cloud-vpcaccess-v1
google-cloud-webrisk-v1	google-cloud-webrisk-v1
google-cloud-websecurityscanner-v1	google-cloud-websecurityscanner-v1
google-cloud-workstations-v1	google-cloud-workstations-v1
google-cloud-container-v1	google-cloud-container-v1
google-cloud-datastore-admin-v1	google-cloud-datastore-admin-v1
google-cloud-artifactregistry-v1	google-cloud-artifactregistry-v1
google-cloud-build-v1	google-cloud-build-v1
google-cloud-build-v2	google-cloud-build-v2
google-cloud-profiler-v2	google-cloud-profiler-v2
google-cloud-trace-v2	google-cloud-trace-v2
google-cloud-containeranalysis-v1	google-cloud-containeranalysis-v1
google-cloud-firestore-admin-v1	google-cloud-firestore-admin-v1
google-cloud-iam-admin-v1	google-cloud-iam-admin-v1
google-cloud-iam-v3	google-cloud-iam-v3
google-cloud-logging-v2	google-cloud-logging-v2
google-cloud-monitoring-dashboard-v1	google-cloud-monitoring-dashboard-v1
google-cloud-monitoring-metricsscope-v1	google-cloud-monitoring-metricsscope-v1
google-cloud-monitoring-v3	google-cloud-monitoring-v3
google-cloud-privacy-dlp-v2	google-cloud-privacy-dlp-v2
google-cloud-spanner-admin-database-v1	google-cloud-spanner-admin-database-v1
google-cloud-spanner-admin-instance-v1	google-cloud-spanner-admin-instance-v1
google-cloud-storagetransfer-v1	google-cloud-storagetransfer-v1


rate gsutilCopy item path
Settings
Help

Summary
Source
🚙 gsutil
Embark Embark Crates.io Docs dependency status Build status

A small, incomplete replacement for the official gsutil.

Why?
You need to do basic GCS operations like uploading some objects for eg. CD, and don’t need to do every possible thing you can do with GCS.
You want a single binary with 0 system dependencies and a minimal footprint (the gcloud/gsutil install is over 100MiB, compressed, in addition to requiring a Python install)
Why not?
This binary only supports some operations, listed below, if you need other operations they need to be added, or you must use the official gsutil.
Supported subcommands
cat - Downloads and prints an object to stdout.
cp - Either downloads an Object and stores it in a local file, or uploads a local file as an Object.
ls - Lists Objects.
signurl - Creates a signed url for an Object.
stat - Shows metadata for an Object.
Contribution
Contributor Covenant

We welcome community contributions to this project.

Please read our Contributor Guide for more information on how to get started. Please also read our Contributor Terms before you make any contributions.

Any contribution intentionally submitted for inclusion in an Embark Studios project, shall comply with the Rust standard licensing model (MIT + Apache 2.0) and therefore be dual licensed as described below, without any additional terms or conditions:

License
This [contribution] is dual licensed under EITHER OF

Apache License, Version 2.0, (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0)
MIT license (LICENSE-MIT or http://opensource.org/licenses/MIT)
at your option.

For clarity, “your” refers to Embark or any other licensee/user of the contribution.

Modules
cat
color
cp
ls
rm
setmeta
signurl
stat
util


tame_gcs::objects
Struct Object Copy item path
Source
Search
Settings
Help

Summary
pub struct Object { /* private fields */ }
Helper struct used to collate all of the operations available for Objects Additionally, it can also be used to specify a custom authority.

Implementations
Source
impl Object
Source
pub fn delete<'a, OID>(
    &self,
    id: &OID,
    optional: Option<DeleteObjectOptional<'_>>,
) -> Result<Request<Empty>, Error>
where
    OID: ObjectIdentifier<'a> + ?Sized,
Deletes an object and its metadata. Deletions are permanent if versioning is not enabled for the bucket, or if the generation parameter is used.

Required IAM Permissions: storage.objects.delete

Complete API documentation

Source
impl Object
Source
pub fn download<'a, OID>(
    &self,
    id: &OID,
    optional: Option<DownloadObjectOptional<'_>>,
) -> Result<Request<Empty>, Error>
where
    OID: ObjectIdentifier<'a> + ?Sized,
Downloads an object

Required IAM Permissions: storage.objects.get, storage.objects.getIamPolicy*

Complete API Documentation

Source


Objects: get

bookmark_border
Retrieves object metadata. When alt=media is included as a query parameter in the request, this method retrieves object data.

This method supports the use of the Range header, which can be used to retrieve only part of the object data.

For examples of performing object downloads with different Cloud Storage tools and client libraries, see the Downloading Objects guide.

Required permissions
The authenticated user must have the storage.objects.get IAM permission to use this method. To return object ACLs, the authenticated user must also have the storage.objects.getIamPolicy permission.

Request
HTTP request

GET https://storage.googleapis.com/storage/v1/b/bucket/o/object
In addition to standard query parameters, the following query parameters apply to this method.

To see an example of how to include query parameters in a request, see the JSON API Overview page.

Parameters
Parameter name	Value	Description
Path parameters
bucket	string	Name of the bucket in which the object resides.
object	string	Name of the object. For information about how to URL encode object names to be path safe, see Encoding URI path parts.
Optional query parameters
alt	string	Type of data to return. Defaults to json.
Acceptable values are:

json: Return object metadata.
media: Return object data. Not supported for soft-deleted objects.
generation	long	If present, selects a specific revision of this object (as opposed to the latest version, the default). If softDeleted is true, this parameter is required.
ifGenerationMatch	long	Makes the operation conditional on whether the object's current generation matches the given value. Setting to 0 makes the operation succeed only if there are no live versions of the object.
ifGenerationNotMatch	long	Makes the operation conditional on whether the object's current generation does not match the given value. If no live object exists, the precondition fails. Setting to 0 makes the operation succeed only if there is a live version of the object.
ifMetagenerationMatch	long	Makes the operation conditional on whether the object's current metageneration matches the given value.
ifMetagenerationNotMatch	long	Makes the operation conditional on whether the object's current metageneration does not match the given value.
projection	string	Set of properties to return. Defaults to noAcl.

Acceptable values are:
full: Include all properties.
noAcl: Omit the owner, acl property.
restoreToken	string	Applicable in buckets with hierarchical namespace enabled. The restoreToken is a universally unique identifier (UUID) associated with each soft-deleted object.
When getting the metadata for a soft-deleted object, the restoreToken is only required when the name and generation values of the object do not uniquely identify it. Otherwise, including a restoreToken in the request is optional.

softDeleted	boolean	If true, returns the metadata of the soft-deleted object. If true, generation must also be specified, and alt=media cannot be specified.
Optional extension headers
X-Goog-Encryption-Algorithm	string	The encryption algorithm to use, which must be AES256. Use this header if the object is encrypted with a customer-supplied encryption key and you want the object's data or content hashes returned in the response.
X-Goog-Encryption-Key	string	An RFC 4648 Base64-encoded string of your AES-256 encryption key. Use this header if the object is encrypted with a customer-supplied encryption key and you want the object's data or content hashes returned in the response.
X-Goog-Encryption-Key-Sha256	string	An RFC 4648 Base64-encoded string of the SHA256 hash of your encryption key. Use this header if the object is encrypted with a customer-supplied encryption key and you want the object's data or content hashes returned in the response.
Request body
Do not supply a request body with this method.

Response
By default, this responds with an object resource in the response body. If you provide the URL parameter alt=media, then it will respond with the object data in the response body.

For information about status and error codes returned by this API, see the reference page.


Objects: copy

bookmark_border
Copies a source object to a destination object. Optionally overrides metadata.

Generally, you should use the rewrite method instead of the copy method: the copy method uses the rewrite method, but calls it exactly once. Larger objects can require multiple rewrite calls, so copy attempts of such objects can lead to Payload too large errors.

Note: The copied object does not retain the ACLs of the original object. Instead, it gains any ACLs you specify in the copy method or, if you don't specify any ACLs, the default object ACLs of the bucket it is stored in.
Required permissions
The authenticated user must have the following IAM permissions to use this method:

storage.objects.create on the destination bucket
storage.objects.delete on the destination bucket, if overwriting an existing object
storage.objects.setRetention on the destination bucket, if the request body includes the retention property
storage.objects.get on the source bucket
storage.objects.createContext on the destination bucket, if the request body includes a non-empty contexts.custom property
Request
HTTP request

POST https://storage.googleapis.com/storage/v1/b/sourceBucket/o/sourceObject/copyTo/b/destinationBucket/o/destinationObject
In addition to standard query parameters, the following query parameters apply to this method.

To see an example of how to include query parameters in a request, see the JSON API Overview page.

Parameters
Parameter name	Value	Description
Path parameters
destinationBucket	string	Name of the bucket in which to store the new object. Overrides the provided object metadata's bucket value, if any. For information about how to URL encode object names to be path safe, see Encoding URI path parts.
destinationObject	string	Name of the new object. Required when the object metadata is not otherwise provided. Overrides the object metadata's name value, if any.
sourceBucket	string	Name of the bucket in which to find the source object.
sourceObject	string	Name of the source object. For information about how to URL encode object names to be path safe, see Encoding URI path parts.
Optional query parameters
destinationKmsKeyName	string	Resource name of the Cloud KMS key that will be used to encrypt the object. The Cloud KMS key must be located in same location as the object.

If the parameter is not specified, the request uses the destination bucket's default encryption key, if any, or else it uses standard Cloud Storage encryption.

If the object is large, re-encryption with the key may take too long and result in a Deadline exceeded error. For large objects, consider using the rewrite method instead.
destinationPredefinedAcl	string	Apply a predefined set of access controls to the destination object.

Acceptable values are:
authenticatedRead: Object owner gets OWNER access, and allAuthenticatedUsers get READER access.
bucketOwnerFullControl: Object owner gets OWNER access, and project team owners get OWNER access.
bucketOwnerRead: Object owner gets OWNER access, and project team owners get READER access.
private: Object owner gets OWNER access.
projectPrivate: Object owner gets OWNER access, and project team members get access according to their roles.
publicRead: Object owner gets OWNER access, and allUsers get READER access.
If iamConfiguration.uniformBucketLevelAccess.enabled is set to true, requests that include this parameter fail with a 400 Bad Request response.
ifGenerationMatch	long	Makes the operation conditional on there being a live destination object with a generation number that matches the given value. Setting ifGenerationMatch to 0 makes the operation succeed only if there is no live destination object.
ifGenerationNotMatch	long	Makes the operation conditional on there being a live destination object with a generation number that does not match the given value. If no live destination object exists, the precondition fails. Setting ifGenerationNotMatch to 0 makes the operation succeed if there is a live version of the object.
ifMetagenerationMatch	long	Makes the operation conditional on there being a live destination object with a metageneration number that matches the given value.
ifMetagenerationNotMatch	long	Makes the operation conditional on there being a live destination object with a metageneration number that does not match the given value.
ifSourceGenerationMatch	long	Makes the operation conditional on whether the source object's generation matches the given value.
ifSourceGenerationNotMatch	long	Makes the operation conditional on whether the source object's generation does not match the given value.
ifSourceMetagenerationMatch	long	Makes the operation conditional on whether the source object's current metageneration matches the given value.
ifSourceMetagenerationNotMatch	long	Makes the operation conditional on whether the source object's current metageneration does not match the given value.
projection	string	Set of properties to return. Defaults to noAcl, unless the object resource specifies the acl property, when it defaults to full.

Acceptable values are:
full: Include all properties.
noAcl: Omit the owner, acl property.
sourceGeneration	long	If present, selects a specific revision of the source object (as opposed to the latest version, the default).
Optional extension headers
X-Goog-Copy-Source-Encryption-Algorithm	string	The encryption algorithm to use, which must be AES256. Used if the source object was encrypted with a customer-supplied encryption key.
X-Goog-Copy-Source-Encryption-Key	string	An RFC 4648 Base64-encoded string of the AES-256 encryption key used to encrypt the source object, if it was encrypted with a customer-supplied encryption key.
X-Goog-Copy-Source-Encryption-Key-Sha256	string	An RFC 4648 Base64-encoded string of the SHA256 hash of the encryption key used to encrypt the source object, if it was encrypted with a customer-supplied encryption key.
X-Goog-Encryption-Algorithm	string	The encryption algorithm to use, which must be AES256. Used for encrypting the destination object with a customer-supplied encryption key.
X-Goog-Encryption-Key	string	An RFC 4648 Base64-encoded string of your AES-256 encryption key. Used for encrypting the destination object with a customer-supplied encryption key.
X-Goog-Encryption-Key-Sha256	string	An RFC 4648 Base64-encoded string of the SHA256 hash of your encryption key. Used for encrypting the destination object with a customer-supplied encryption key.
Request body
In the request body, supply metadata to apply to the destination object by using an object resource. If the request body is empty, editable metadata from the source object is applied to the destination object, with the exception of any ACLs, object holds, or retention configuration set on the source object. If you want to retain these from the original object, they must be included in the request body.

Response
If successful, this method returns an object resource in the response body.

For information about status and error codes returned by this API, see the reference page.
gsutil
Module cpCopy item path
Settings
Help

Summary
Source
Structs
Args
Functions
cmd


gsutil/
cp.rs
Settings
Help

Summary
use crate::util;
use anyhow::Context as _;
use std::{convert::TryFrom, path::PathBuf};
use tame_gcs::objects::{self, Metadata};

#[derive(clap::ValueEnum, Clone, Copy)]
enum Acl {
    ProjectPrivate,
    Private,
    PublicRead,
    AuthenticatedRead,
    BucketOwnerRead,
    BucketOwnerFullControl,
}

impl From<Acl> for tame_gcs::common::PredefinedAcl {
    fn from(a: Acl) -> Self {
        match a {
            Acl::ProjectPrivate => Self::ProjectPrivate,
            Acl::Private => Self::Private,
            Acl::PublicRead => Self::PublicRead,
            Acl::AuthenticatedRead => Self::AuthenticatedRead,
            Acl::BucketOwnerRead => Self::BucketOwnerRead,
            Acl::BucketOwnerFullControl => Self::BucketOwnerFullControl,
        }
    }
}

#[derive(clap::Parser)]
pub struct Args {
    /// Predefined ACL to apply to the destination GCS object
    #[clap(short = 'a')]
    predef_acl: Option<Acl>,
    /// A gs: URL or filepath for the source path to copy from,
    /// wildcards are not currently supported
    src_url: String,
    /// A gs: URL or filepath for the destination to copy to,
    /// wildcards are not currently supported
    dest_url: String,
}

enum DataPath {
    Gs(util::GsUrl),
    Local(PathBuf),
}

impl DataPath {
    #[inline]
    fn is_local(&self) -> bool {
        matches!(self, Self::Local(_))
    }
}

impl TryFrom<String> for DataPath {
    type Error = anyhow::Error;

    fn try_from(s: String) -> anyhow::Result<Self> {
        if s.starts_with("gs://") {
            let url = url::Url::parse(&s)?;
            Ok(Self::Gs(util::gs_url_to_object_id(&url)?))
        } else {
            Ok(Self::Local(PathBuf::from(s)))
        }
    }
}

// cp is probably gsutil's most complicated subcommand, so we only implement
// a bare minimum
pub async fn cmd(ctx: &util::RequestContext, args: Args) -> anyhow::Result<()> {
    use std::fs;

    let src = DataPath::try_from(args.src_url)?;
    let dst = DataPath::try_from(args.dest_url)?;

    // Just support gcs to local or vice versa, not local to local or gcs to gcs
    if src.is_local() == dst.is_local() {
        let location = if src.is_local() { "local disk" } else { "gcs" };

        anyhow::bail!("source and destination are both located on {location}")
    }

    match (&src, &dst) {
        (DataPath::Local(ref src), DataPath::Gs(dst)) => {
            let src_file = fs::File::open(src).context("source path")?;
            let src_len = src_file.metadata()?.len();

            let optional = args.predef_acl.map(|acl| objects::InsertObjectOptional {
                predefined_acl: Some(acl.into()),
                ..Default::default()
            });

            let insert_req = ctx.obj.insert_multipart(
                dst.bucket(),
                src_file,
                src_len,
                &Metadata {
                    name: dst.object().map(|obn| obn.to_string()),
                    content_encoding: Some("identity".to_owned()),
                    ..Default::default()
                },
                optional,
            )?;

            let _insert_res: objects::InsertResponse = util::execute(ctx, insert_req).await?;

            Ok(())
        }
        (DataPath::Gs(src), DataPath::Local(dst)) => {
            let mut dst_file = fs::File::create(dst).context("destination path")?;

            let dl_req = ctx.obj.download(
                &(
                    src.bucket(),
                    src.object()
                        .context("must provide a full object name to copy from")?,
                ),
                None,
            )?;

            let mut response: objects::DownloadObjectResponse = util::execute(ctx, dl_req).await?;

            std::io::copy(&mut response, &mut dst_file)?;

            Ok(())
        }
        _ => unreachable!(),
    }
}


gsutil
Module utilCopy item path
Settings
Help

Summary
Source
Structs
GsUrl
RequestContext
Functions
execute
Executes a GCS request via a reqwest client and returns the parsed response/API error
gs_url_to_object_id
Converts a gs://<bucket_name>/<object_name> url into a regular object identifier
